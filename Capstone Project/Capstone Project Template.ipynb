{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# US Immigration Data with Detailed Profile of Entry/Destination States and Cities\n",
    "## Data Engineering Capstone Project\n",
    "\n",
    "### Project Summary\n",
    "The purpose of this project is to gather and transform US immigration data and its related data including US demographic data, temperature data, and crime data, so that one can obtain more detailed analysis results on the US immigration data.\n",
    "\n",
    "The project follows the follow steps:\n",
    "* Step 1: Scope the Project and Gather Data\n",
    "* Step 2: Explore and Assess the Data\n",
    "* Step 3: Define the Data Model\n",
    "* Step 4: Run ETL to Model the Data\n",
    "* Step 5: Complete Project Write Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do all imports and installs here\n",
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "import glob\n",
    "import psycopg2\n",
    "import pandas as pd\n",
    "from sql_queries import *\n",
    "from pyspark.sql import SparkSession\n",
    "from datetime import datetime\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql import types as T\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql.functions import *\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Scope the Project and Gather Data\n",
    "\n",
    "### Scope \n",
    "#### Solution goal:\n",
    "The goal is to create a database schema that consists of 1 fact table and 4 dimension tables.  \n",
    "- A **fact** table would be **immigration** table, created by combining Immigration data with different data sources whose primary key would be *id*.\n",
    "- The first **dimension** table would be **demographic** table, whose primary key would be *state*.\n",
    "- The second **dimension** table would be **crime** table, whose composite key would be *county_name* and *state_name*.\n",
    "- The third **dimension** table would be **temperature** table, whose composite key would be *county* and *state*.\n",
    "- The last **dimension** table would be **date** table, whose primary key would be *created_date*.\n",
    "\n",
    "\n",
    "#### Data to use:\n",
    "- `I94 Immigration Data` - US Immigration data of 2016 from \"US National Tourism and Trade Office\". It includes information about immigrants such as origin city, reason for immigration, visa type, gender, birth year, flight number and so on. \n",
    "- `I94_SAS_Labels_Descriptions.SAS` - Text file which includes lists of codes and corresponding lables for the `I94 Immigration Data`.\n",
    "- `us-cities-demographics.csv`   - Basic demographic information of the US of 2015 which comes from \"OpenSoft\". It includes statistics by state, city, race, age, gender and so on.\n",
    "- `airport-codes.csv.csv`  -  List of all airport codes which comes from \"DATA HUB\". It includes airport information such as airpot type, name, municipality and so on.\n",
    "- `Offenses_Known_to_Law_Enforcement.xls`   - Number of crimes by US state and metropolitan and non-metropolitan country of 2015 which comes from \"data.world\". It includes number of crimes in each crime category in the US.\n",
    "- `GlobalLandTemperaturesByCity.csv` - Global temperature information since 1970s by country and cities which come from \"Kaggle\". It includes monthly average temperatures.\n",
    "- `uscities.csv` - Basic information about US cities, counties, and states.\n",
    "\n",
    "\n",
    "#### Tool to use:\n",
    "- `Jupyter Notebook`\n",
    "- `Python`\n",
    "- `Pandas`\n",
    "- `PySpark`\n",
    "- `PostgreSQL`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating spark cluster\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.\\\n",
    "config(\"spark.jars.packages\",\"saurfang:spark-sas7bdat:2.0.0-s_2.11\")\\\n",
    ".enableHiveSupport().getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading in the immigration data\n",
    "immigration_data=spark.read.parquet(\"sas_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3096313"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking number of records in the immigration data\n",
    "immigration_data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>cicid</th>\n",
       "      <th>i94yr</th>\n",
       "      <th>i94mon</th>\n",
       "      <th>i94cit</th>\n",
       "      <th>i94res</th>\n",
       "      <th>i94port</th>\n",
       "      <th>arrdate</th>\n",
       "      <th>i94mode</th>\n",
       "      <th>i94addr</th>\n",
       "      <th>...</th>\n",
       "      <th>entdepu</th>\n",
       "      <th>matflag</th>\n",
       "      <th>biryear</th>\n",
       "      <th>dtaddto</th>\n",
       "      <th>gender</th>\n",
       "      <th>insnum</th>\n",
       "      <th>airline</th>\n",
       "      <th>admnum</th>\n",
       "      <th>fltno</th>\n",
       "      <th>visatype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2027561</td>\n",
       "      <td>4084316.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>209.0</td>\n",
       "      <td>209.0</td>\n",
       "      <td>HHW</td>\n",
       "      <td>20566.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>HI</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1955.0</td>\n",
       "      <td>07202016</td>\n",
       "      <td>F</td>\n",
       "      <td>NaN</td>\n",
       "      <td>JL</td>\n",
       "      <td>5.658267e+10</td>\n",
       "      <td>00782</td>\n",
       "      <td>WT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2171295</td>\n",
       "      <td>4422636.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>582.0</td>\n",
       "      <td>582.0</td>\n",
       "      <td>MCA</td>\n",
       "      <td>20567.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>TX</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1990.0</td>\n",
       "      <td>10222016</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>*GA</td>\n",
       "      <td>9.436200e+10</td>\n",
       "      <td>XBLNG</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>589494</td>\n",
       "      <td>1195600.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>OGG</td>\n",
       "      <td>20551.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>FL</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1940.0</td>\n",
       "      <td>07052016</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LH</td>\n",
       "      <td>5.578047e+10</td>\n",
       "      <td>00464</td>\n",
       "      <td>WT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2631158</td>\n",
       "      <td>5291768.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>297.0</td>\n",
       "      <td>297.0</td>\n",
       "      <td>LOS</td>\n",
       "      <td>20572.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CA</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1991.0</td>\n",
       "      <td>10272016</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>QR</td>\n",
       "      <td>9.478970e+10</td>\n",
       "      <td>00739</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3032257</td>\n",
       "      <td>985523.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>CHM</td>\n",
       "      <td>20550.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NY</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1997.0</td>\n",
       "      <td>07042016</td>\n",
       "      <td>F</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.232257e+10</td>\n",
       "      <td>LAND</td>\n",
       "      <td>WT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0      cicid   i94yr  i94mon  i94cit  i94res i94port  arrdate  \\\n",
       "0     2027561  4084316.0  2016.0     4.0   209.0   209.0     HHW  20566.0   \n",
       "1     2171295  4422636.0  2016.0     4.0   582.0   582.0     MCA  20567.0   \n",
       "2      589494  1195600.0  2016.0     4.0   148.0   112.0     OGG  20551.0   \n",
       "3     2631158  5291768.0  2016.0     4.0   297.0   297.0     LOS  20572.0   \n",
       "4     3032257   985523.0  2016.0     4.0   111.0   111.0     CHM  20550.0   \n",
       "\n",
       "   i94mode i94addr    ...     entdepu  matflag  biryear   dtaddto  gender  \\\n",
       "0      1.0      HI    ...         NaN        M   1955.0  07202016       F   \n",
       "1      1.0      TX    ...         NaN        M   1990.0  10222016       M   \n",
       "2      1.0      FL    ...         NaN        M   1940.0  07052016       M   \n",
       "3      1.0      CA    ...         NaN        M   1991.0  10272016       M   \n",
       "4      3.0      NY    ...         NaN        M   1997.0  07042016       F   \n",
       "\n",
       "  insnum airline        admnum  fltno  visatype  \n",
       "0    NaN      JL  5.658267e+10  00782        WT  \n",
       "1    NaN     *GA  9.436200e+10  XBLNG        B2  \n",
       "2    NaN      LH  5.578047e+10  00464        WT  \n",
       "3    NaN      QR  9.478970e+10  00739        B2  \n",
       "4    NaN     NaN  4.232257e+10   LAND        WT  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in the sample data of the immigration data and show the first few rows to see what the contents look like.\n",
    "fname = 'immigration_data_sample.csv'\n",
    "df_imgr = pd.read_csv(fname)\n",
    "df_imgr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>County</th>\n",
       "      <th>Violent_crime</th>\n",
       "      <th>Murder_and_nonnegligent_manslaughter</th>\n",
       "      <th>Rape_1</th>\n",
       "      <th>Rape_2</th>\n",
       "      <th>Robbery</th>\n",
       "      <th>Aggravated_assault</th>\n",
       "      <th>Property_crime</th>\n",
       "      <th>Burglary</th>\n",
       "      <th>Larceny-theft</th>\n",
       "      <th>Motor_vehicle_theft</th>\n",
       "      <th>Arson3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ALABAMA - Metropolitan Counties</td>\n",
       "      <td>Autauga</td>\n",
       "      <td>69</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>50</td>\n",
       "      <td>344.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>187.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ALABAMA - Metropolitan Counties</td>\n",
       "      <td>Baldwin</td>\n",
       "      <td>115</td>\n",
       "      <td>0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33</td>\n",
       "      <td>73</td>\n",
       "      <td>648.0</td>\n",
       "      <td>225.0</td>\n",
       "      <td>390.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ALABAMA - Metropolitan Counties</td>\n",
       "      <td>Bibb</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>41.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ALABAMA - Metropolitan Counties</td>\n",
       "      <td>Blount</td>\n",
       "      <td>204</td>\n",
       "      <td>5</td>\n",
       "      <td>16.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>178</td>\n",
       "      <td>832.0</td>\n",
       "      <td>247.0</td>\n",
       "      <td>503.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ALABAMA - Metropolitan Counties</td>\n",
       "      <td>Calhoun</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>413.0</td>\n",
       "      <td>181.0</td>\n",
       "      <td>225.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             State   County  Violent_crime  \\\n",
       "0  ALABAMA - Metropolitan Counties  Autauga             69   \n",
       "1  ALABAMA - Metropolitan Counties  Baldwin            115   \n",
       "2  ALABAMA - Metropolitan Counties     Bibb              7   \n",
       "3  ALABAMA - Metropolitan Counties   Blount            204   \n",
       "4  ALABAMA - Metropolitan Counties  Calhoun             16   \n",
       "\n",
       "   Murder_and_nonnegligent_manslaughter  Rape_1  Rape_2  Robbery  \\\n",
       "0                                     0    13.0     NaN        6   \n",
       "1                                     0     9.0     NaN       33   \n",
       "2                                     0     2.0     NaN        1   \n",
       "3                                     5    16.0     NaN        5   \n",
       "4                                     0     4.0     NaN        1   \n",
       "\n",
       "   Aggravated_assault  Property_crime  Burglary  Larceny-theft  \\\n",
       "0                  50           344.0     111.0          187.0   \n",
       "1                  73           648.0     225.0          390.0   \n",
       "2                   4            41.0      20.0           18.0   \n",
       "3                 178           832.0     247.0          503.0   \n",
       "4                  11           413.0     181.0          225.0   \n",
       "\n",
       "   Motor_vehicle_theft  Arson3  \n",
       "0                 46.0     NaN  \n",
       "1                 33.0     NaN  \n",
       "2                  3.0     NaN  \n",
       "3                 82.0     NaN  \n",
       "4                  7.0     NaN  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in the crime data\n",
    "df_crime = pd.read_excel('Offenses_Known_to_Law_Enforcement.xls', \n",
    "                         header=4, \n",
    "                         names=[\"State\",\n",
    "                                \"County\",\n",
    "                                \"Violent_crime\",\n",
    "                                \"Murder_and_nonnegligent_manslaughter\",\n",
    "                                \"Rape_1\",\n",
    "                                \"Rape_2\",\n",
    "                                \"Robbery\",\n",
    "                                \"Aggravated_assault\",\n",
    "                                \"Property_crime\",\n",
    "                                \"Burglary\",\n",
    "                                \"Larceny-theft\",\n",
    "                                \"Motor_vehicle_theft\",\n",
    "                                \"Arson3\"])\n",
    "df_crime.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Median Age</th>\n",
       "      <th>Male Population</th>\n",
       "      <th>Female Population</th>\n",
       "      <th>Total Population</th>\n",
       "      <th>Number of Veterans</th>\n",
       "      <th>Foreign-born</th>\n",
       "      <th>Average Household Size</th>\n",
       "      <th>State Code</th>\n",
       "      <th>Race</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Silver Spring</td>\n",
       "      <td>Maryland</td>\n",
       "      <td>33.8</td>\n",
       "      <td>40601</td>\n",
       "      <td>41862</td>\n",
       "      <td>82463</td>\n",
       "      <td>1562</td>\n",
       "      <td>30908</td>\n",
       "      <td>2.6</td>\n",
       "      <td>MD</td>\n",
       "      <td>Hispanic or Latino</td>\n",
       "      <td>25924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Quincy</td>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>41.0</td>\n",
       "      <td>44129</td>\n",
       "      <td>49500</td>\n",
       "      <td>93629</td>\n",
       "      <td>4147</td>\n",
       "      <td>32935</td>\n",
       "      <td>2.39</td>\n",
       "      <td>MA</td>\n",
       "      <td>White</td>\n",
       "      <td>58723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hoover</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>38.5</td>\n",
       "      <td>38040</td>\n",
       "      <td>46799</td>\n",
       "      <td>84839</td>\n",
       "      <td>4819</td>\n",
       "      <td>8229</td>\n",
       "      <td>2.58</td>\n",
       "      <td>AL</td>\n",
       "      <td>Asian</td>\n",
       "      <td>4759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Rancho Cucamonga</td>\n",
       "      <td>California</td>\n",
       "      <td>34.5</td>\n",
       "      <td>88127</td>\n",
       "      <td>87105</td>\n",
       "      <td>175232</td>\n",
       "      <td>5821</td>\n",
       "      <td>33878</td>\n",
       "      <td>3.18</td>\n",
       "      <td>CA</td>\n",
       "      <td>Black or African-American</td>\n",
       "      <td>24437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Newark</td>\n",
       "      <td>New Jersey</td>\n",
       "      <td>34.6</td>\n",
       "      <td>138040</td>\n",
       "      <td>143873</td>\n",
       "      <td>281913</td>\n",
       "      <td>5829</td>\n",
       "      <td>86253</td>\n",
       "      <td>2.73</td>\n",
       "      <td>NJ</td>\n",
       "      <td>White</td>\n",
       "      <td>76402</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "0              City          State Median Age Male Population  \\\n",
       "0     Silver Spring       Maryland       33.8           40601   \n",
       "1            Quincy  Massachusetts       41.0           44129   \n",
       "2            Hoover        Alabama       38.5           38040   \n",
       "3  Rancho Cucamonga     California       34.5           88127   \n",
       "4            Newark     New Jersey       34.6          138040   \n",
       "\n",
       "0 Female Population Total Population Number of Veterans Foreign-born  \\\n",
       "0             41862            82463               1562        30908   \n",
       "1             49500            93629               4147        32935   \n",
       "2             46799            84839               4819         8229   \n",
       "3             87105           175232               5821        33878   \n",
       "4            143873           281913               5829        86253   \n",
       "\n",
       "0 Average Household Size State Code                       Race  Count  \n",
       "0                    2.6         MD         Hispanic or Latino  25924  \n",
       "1                   2.39         MA                      White  58723  \n",
       "2                   2.58         AL                      Asian   4759  \n",
       "3                   3.18         CA  Black or African-American  24437  \n",
       "4                   2.73         NJ                      White  76402  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in the us demographic data\n",
    "df_demo = pd.read_csv('us-cities-demographics.csv', header=None)\n",
    "\n",
    "\n",
    "# Split a column which has multiple values into separate columns and set it as a dataframe\n",
    "df_demo = df_demo[0].str.split(\";\",expand = True)\n",
    "df_demo = pd.DataFrame(df_demo)\n",
    "\n",
    "# Change headers\n",
    "headers = df_demo.iloc[0]\n",
    "df_demo  = pd.DataFrame(df_demo.values[1:], columns=headers)\n",
    "\n",
    "df_demo.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dt</th>\n",
       "      <th>AverageTemperature</th>\n",
       "      <th>AverageTemperatureUncertainty</th>\n",
       "      <th>City</th>\n",
       "      <th>Country</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1743-11-01</td>\n",
       "      <td>6.068</td>\n",
       "      <td>1.737</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1743-12-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1744-01-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1744-02-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1744-03-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           dt  AverageTemperature  AverageTemperatureUncertainty   City  \\\n",
       "0  1743-11-01               6.068                          1.737  Århus   \n",
       "1  1743-12-01                 NaN                            NaN  Århus   \n",
       "2  1744-01-01                 NaN                            NaN  Århus   \n",
       "3  1744-02-01                 NaN                            NaN  Århus   \n",
       "4  1744-03-01                 NaN                            NaN  Århus   \n",
       "\n",
       "   Country Latitude Longitude  \n",
       "0  Denmark   57.05N    10.33E  \n",
       "1  Denmark   57.05N    10.33E  \n",
       "2  Denmark   57.05N    10.33E  \n",
       "3  Denmark   57.05N    10.33E  \n",
       "4  Denmark   57.05N    10.33E  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in Temperature data\n",
    "df_temp = pd.read_csv('../../data2/GlobalLandTemperaturesByCity.csv')\n",
    "df_temp.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>city_ascii</th>\n",
       "      <th>state_id</th>\n",
       "      <th>state_name</th>\n",
       "      <th>county_fips</th>\n",
       "      <th>county_name</th>\n",
       "      <th>lat</th>\n",
       "      <th>lng</th>\n",
       "      <th>population</th>\n",
       "      <th>density</th>\n",
       "      <th>source</th>\n",
       "      <th>military</th>\n",
       "      <th>incorporated</th>\n",
       "      <th>timezone</th>\n",
       "      <th>ranking</th>\n",
       "      <th>zips</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>New York</td>\n",
       "      <td>New York</td>\n",
       "      <td>NY</td>\n",
       "      <td>New York</td>\n",
       "      <td>36061</td>\n",
       "      <td>New York</td>\n",
       "      <td>40.6943</td>\n",
       "      <td>-73.9249</td>\n",
       "      <td>18713220</td>\n",
       "      <td>10715</td>\n",
       "      <td>polygon</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>America/New_York</td>\n",
       "      <td>1</td>\n",
       "      <td>11229 11226 11225 11224 11222 11221 11220 1138...</td>\n",
       "      <td>1840034016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>CA</td>\n",
       "      <td>California</td>\n",
       "      <td>6037</td>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>34.1139</td>\n",
       "      <td>-118.4068</td>\n",
       "      <td>12750807</td>\n",
       "      <td>3276</td>\n",
       "      <td>polygon</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>America/Los_Angeles</td>\n",
       "      <td>1</td>\n",
       "      <td>90291 90293 90292 91316 91311 90037 90031 9000...</td>\n",
       "      <td>1840020491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Chicago</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>IL</td>\n",
       "      <td>Illinois</td>\n",
       "      <td>17031</td>\n",
       "      <td>Cook</td>\n",
       "      <td>41.8373</td>\n",
       "      <td>-87.6862</td>\n",
       "      <td>8604203</td>\n",
       "      <td>4574</td>\n",
       "      <td>polygon</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>America/Chicago</td>\n",
       "      <td>1</td>\n",
       "      <td>60018 60649 60641 60640 60643 60642 60645 6064...</td>\n",
       "      <td>1840000494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Miami</td>\n",
       "      <td>Miami</td>\n",
       "      <td>FL</td>\n",
       "      <td>Florida</td>\n",
       "      <td>12086</td>\n",
       "      <td>Miami-Dade</td>\n",
       "      <td>25.7839</td>\n",
       "      <td>-80.2102</td>\n",
       "      <td>6445545</td>\n",
       "      <td>5019</td>\n",
       "      <td>polygon</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>America/New_York</td>\n",
       "      <td>1</td>\n",
       "      <td>33129 33125 33126 33127 33128 33149 33144 3314...</td>\n",
       "      <td>1840015149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dallas</td>\n",
       "      <td>Dallas</td>\n",
       "      <td>TX</td>\n",
       "      <td>Texas</td>\n",
       "      <td>48113</td>\n",
       "      <td>Dallas</td>\n",
       "      <td>32.7936</td>\n",
       "      <td>-96.7662</td>\n",
       "      <td>5743938</td>\n",
       "      <td>1526</td>\n",
       "      <td>polygon</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>America/Chicago</td>\n",
       "      <td>1</td>\n",
       "      <td>75287 75098 75233 75254 75251 75252 75253 7503...</td>\n",
       "      <td>1840019440</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          city   city_ascii state_id  state_name  county_fips  county_name  \\\n",
       "0     New York     New York       NY    New York        36061     New York   \n",
       "1  Los Angeles  Los Angeles       CA  California         6037  Los Angeles   \n",
       "2      Chicago      Chicago       IL    Illinois        17031         Cook   \n",
       "3        Miami        Miami       FL     Florida        12086   Miami-Dade   \n",
       "4       Dallas       Dallas       TX       Texas        48113       Dallas   \n",
       "\n",
       "       lat       lng  population  density   source  military  incorporated  \\\n",
       "0  40.6943  -73.9249    18713220    10715  polygon     False          True   \n",
       "1  34.1139 -118.4068    12750807     3276  polygon     False          True   \n",
       "2  41.8373  -87.6862     8604203     4574  polygon     False          True   \n",
       "3  25.7839  -80.2102     6445545     5019  polygon     False          True   \n",
       "4  32.7936  -96.7662     5743938     1526  polygon     False          True   \n",
       "\n",
       "              timezone  ranking  \\\n",
       "0     America/New_York        1   \n",
       "1  America/Los_Angeles        1   \n",
       "2      America/Chicago        1   \n",
       "3     America/New_York        1   \n",
       "4      America/Chicago        1   \n",
       "\n",
       "                                                zips          id  \n",
       "0  11229 11226 11225 11224 11222 11221 11220 1138...  1840034016  \n",
       "1  90291 90293 90292 91316 91311 90037 90031 9000...  1840020491  \n",
       "2  60018 60649 60641 60640 60643 60642 60645 6064...  1840000494  \n",
       "3  33129 33125 33126 33127 33128 33149 33144 3314...  1840015149  \n",
       "4  75287 75098 75233 75254 75251 75252 75253 7503...  1840019440  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in US cities data\n",
    "df_label = pd.read_csv('uscities.csv')\n",
    "df_label.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>local_code</th>\n",
       "      <th>airport_name</th>\n",
       "      <th>entry_state_id</th>\n",
       "      <th>entry_county</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00A</td>\n",
       "      <td>Total Rf Heliport</td>\n",
       "      <td>PA</td>\n",
       "      <td>Bensalem</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00AA</td>\n",
       "      <td>Aero B Ranch Airport</td>\n",
       "      <td>KS</td>\n",
       "      <td>Leoti</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00AK</td>\n",
       "      <td>Lowell Field</td>\n",
       "      <td>AK</td>\n",
       "      <td>Anchor Point</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00AL</td>\n",
       "      <td>Epps Airpark</td>\n",
       "      <td>AL</td>\n",
       "      <td>Harvest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Newport Hospital &amp; Clinic Heliport</td>\n",
       "      <td>AR</td>\n",
       "      <td>Newport</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  local_code                        airport_name entry_state_id  entry_county\n",
       "0        00A                   Total Rf Heliport             PA      Bensalem\n",
       "1       00AA                Aero B Ranch Airport             KS         Leoti\n",
       "2       00AK                        Lowell Field             AK  Anchor Point\n",
       "3       00AL                        Epps Airpark             AL       Harvest\n",
       "4        NaN  Newport Hospital & Clinic Heliport             AR       Newport"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in airport data\n",
    "df_airport = pd.read_csv('airport-codes_csv.csv')\n",
    "df_airport = df_airport.rename(\n",
    "    columns={'name': 'airport_name',\n",
    "             'iso_region':'entry_state_id',\n",
    "             'municipality':'entry_county'})\n",
    "df_airport = df_airport[df_airport['entry_state_id'].str.contains('US-')]\n",
    "df_airport['entry_state_id'] = [x.replace('US-','') for x in df_airport['entry_state_id']]\n",
    "df_airport = df_airport[['local_code',\n",
    "                         'airport_name',\n",
    "                         'entry_state_id',\n",
    "                         'entry_county']]\n",
    "df_airport.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Explore and Assess the Data\n",
    "#### Explore the Data \n",
    "Identify data quality issues, like missing values, duplicate data, etc.\n",
    "\n",
    "\n",
    "#### Cleaning Steps\n",
    "\n",
    "- US Demographic data\n",
    "   (Data: `us-cities-demographics.csv`)\n",
    "  1. Change data types of each column\n",
    "  2. Format columns to keep consistensy among other tables\n",
    "  3. Break down 'race' column into separate columns for each racial groups and sum up the numbers by each state\n",
    "  4. Select and sort columns to finalize the Demographic table\n",
    "\n",
    "\n",
    "- Crime data\n",
    "   (Data: `Offenses_Known_to_Law_Enforcement.xls`, `uscities.csv`)\n",
    "  1. Split a column which has more than 1 elements into separate columns\n",
    "  2. Change data types of each column\n",
    "  3. Sum up some of the column values to simplify the table. Also get a total value for all crime numbers\n",
    "  4. Join with `uscities.csv` table to acquire total population of each county\n",
    "  5. Calculate crime rate by county\n",
    "  6. Select, sort and rename columns to finalize table\n",
    "\n",
    "\n",
    "- Immigiration data\n",
    "    (Data: `I94 Immigration Data`, `I94_SAS_Labels_Descriptions.SAS`, `uscities.csv`, - `airport-codes.csv.csv` )\n",
    "  1. For those columns that have many missing values or that are not important for this project, deleted them, change column data types, and rename column names to make it more understandable\n",
    "  2. In order to add label columns from other tables to Immigration table for acquiring code lables, format `I94_SAS_Labels_Descriptions.SAS` and `uscities.csv` file to join\n",
    "  3. Create and format label tables for ports, countries, and visa\n",
    "  4. Format `uscities.csv` table to join state names\n",
    "  5. Convert pandas dataframes to pyspark dataframes for joining with `I94 Immigration Data` table\n",
    "  6. Join converted dataframes with `I94 Immigration Data` table to add label columns\n",
    "  7. Select and sort columns, filter to finalize the Immigiration table\n",
    "\n",
    "\n",
    "- Temperature data\n",
    "    (Data: `GlobalLandTemperaturesByCity.csv`, `uscities.csv`)\n",
    "  1. Format `uscities.csv` table to join with `GlobalLandTemperaturesByCity.csv` table\n",
    "  2. Delete rows with null values, filter with only US data\n",
    "  3. Aggregate table to get avg, min, and max value of temperature for each city\n",
    "  4. Join with uscities table to add county column\n",
    "  5. Select and sort columns to finalize the Temperature table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>state_code</th>\n",
       "      <th>population</th>\n",
       "      <th>median_age</th>\n",
       "      <th>male_population</th>\n",
       "      <th>female_population</th>\n",
       "      <th>number_of_veterans</th>\n",
       "      <th>foreign_born</th>\n",
       "      <th>average_household_size</th>\n",
       "      <th>AmericanIndian_and_AlaskaNative_population</th>\n",
       "      <th>Asian_population</th>\n",
       "      <th>Black_or_AfricanAmerican_population</th>\n",
       "      <th>Hispanic_or_Latino_population</th>\n",
       "      <th>White_population</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ALABAMA</td>\n",
       "      <td>AL</td>\n",
       "      <td>1096154</td>\n",
       "      <td>38.0</td>\n",
       "      <td>2448200</td>\n",
       "      <td>2715106</td>\n",
       "      <td>352896</td>\n",
       "      <td>252541</td>\n",
       "      <td>2.00</td>\n",
       "      <td>8084</td>\n",
       "      <td>28769</td>\n",
       "      <td>521068</td>\n",
       "      <td>39313</td>\n",
       "      <td>498920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ALASKA</td>\n",
       "      <td>AK</td>\n",
       "      <td>336228</td>\n",
       "      <td>32.2</td>\n",
       "      <td>764725</td>\n",
       "      <td>728750</td>\n",
       "      <td>137460</td>\n",
       "      <td>166290</td>\n",
       "      <td>2.00</td>\n",
       "      <td>36339</td>\n",
       "      <td>36825</td>\n",
       "      <td>23107</td>\n",
       "      <td>27261</td>\n",
       "      <td>212696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ARIZONA</td>\n",
       "      <td>AZ</td>\n",
       "      <td>5754881</td>\n",
       "      <td>34.1</td>\n",
       "      <td>11137275</td>\n",
       "      <td>11360435</td>\n",
       "      <td>1322525</td>\n",
       "      <td>3411565</td>\n",
       "      <td>2.19</td>\n",
       "      <td>129708</td>\n",
       "      <td>229183</td>\n",
       "      <td>296222</td>\n",
       "      <td>1508157</td>\n",
       "      <td>3591611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ARKANSAS</td>\n",
       "      <td>AR</td>\n",
       "      <td>643597</td>\n",
       "      <td>32.6</td>\n",
       "      <td>1400724</td>\n",
       "      <td>1482165</td>\n",
       "      <td>154390</td>\n",
       "      <td>307753</td>\n",
       "      <td>2.17</td>\n",
       "      <td>9381</td>\n",
       "      <td>22062</td>\n",
       "      <td>149608</td>\n",
       "      <td>77813</td>\n",
       "      <td>384733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CALIFORNIA</td>\n",
       "      <td>CA</td>\n",
       "      <td>31753718</td>\n",
       "      <td>35.8</td>\n",
       "      <td>61055672</td>\n",
       "      <td>62388681</td>\n",
       "      <td>4617022</td>\n",
       "      <td>37059662</td>\n",
       "      <td>2.59</td>\n",
       "      <td>401386</td>\n",
       "      <td>4543730</td>\n",
       "      <td>2047009</td>\n",
       "      <td>9856464</td>\n",
       "      <td>14905129</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        state state_code  population  median_age  male_population  \\\n",
       "0     ALABAMA         AL     1096154        38.0          2448200   \n",
       "1      ALASKA         AK      336228        32.2           764725   \n",
       "2     ARIZONA         AZ     5754881        34.1         11137275   \n",
       "3    ARKANSAS         AR      643597        32.6          1400724   \n",
       "4  CALIFORNIA         CA    31753718        35.8         61055672   \n",
       "\n",
       "   female_population  number_of_veterans  foreign_born  \\\n",
       "0            2715106              352896        252541   \n",
       "1             728750              137460        166290   \n",
       "2           11360435             1322525       3411565   \n",
       "3            1482165              154390        307753   \n",
       "4           62388681             4617022      37059662   \n",
       "\n",
       "   average_household_size  AmericanIndian_and_AlaskaNative_population  \\\n",
       "0                    2.00                                        8084   \n",
       "1                    2.00                                       36339   \n",
       "2                    2.19                                      129708   \n",
       "3                    2.17                                        9381   \n",
       "4                    2.59                                      401386   \n",
       "\n",
       "   Asian_population  Black_or_AfricanAmerican_population  \\\n",
       "0             28769                               521068   \n",
       "1             36825                                23107   \n",
       "2            229183                               296222   \n",
       "3             22062                               149608   \n",
       "4           4543730                              2047009   \n",
       "\n",
       "   Hispanic_or_Latino_population  White_population  \n",
       "0                          39313            498920  \n",
       "1                          27261            212696  \n",
       "2                        1508157           3591611  \n",
       "3                          77813            384733  \n",
       "4                        9856464          14905129  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cleaning US Demographic table\n",
    "\n",
    "# Change data type of each column\n",
    "cols = ['Male Population',\n",
    "        'Female Population',\n",
    "        'Number of Veterans',\n",
    "       'Foreign-born',\n",
    "        'Average Household Size',\n",
    "        'Count']\n",
    "df_demo[cols] = df_demo[cols].apply(pd.to_numeric, \n",
    "                                    errors='coerce', \n",
    "                                    axis=1).fillna(0.0)\n",
    "df_demo = df_demo.astype({'Median Age': float, \n",
    "                          'Male Population': int, \n",
    "                          'Female Population': int,\n",
    "                          'Number of Veterans':int, \n",
    "                           'Foreign-born':int, \n",
    "                          'Average Household Size':int, \n",
    "                          'Count':int})\n",
    "\n",
    "# Format a column to make it upper case to keep consistensy among other tables\n",
    "df_demo['State'] = df_demo['State'].str.upper()\n",
    "\n",
    "# Break down 'race' column into separate columns for each racial groups and get the sum numbers of each state\n",
    "df_demo_race = df_demo.groupby(['State','Race'])\\\n",
    ".agg({'Count':'sum'})\\\n",
    ".unstack(fill_value=0)\\\n",
    ".reset_index()\n",
    "df_demo_race.columns = df_demo_race.columns.droplevel(0)\n",
    "df_demo_race = df_demo_race.rename(columns={\"\":'State'})\n",
    "df_demo = df_demo.groupby(['State']).agg({'State Code':'max',\n",
    "                                          'Count':'sum',\n",
    "                                          'Median Age':'median',\n",
    "                                          'Male Population':'sum',\n",
    "                                         'Female Population':'sum',\n",
    "                                          'Number of Veterans':'sum',\n",
    "                                          'Foreign-born':'sum',\n",
    "                                         'Average Household Size':'mean'})\n",
    "df_demo['Average Household Size'] = df_demo['Average Household Size'].round(2)\n",
    "df_demo = pd.merge(df_demo, df_demo_race, left_on='State', right_on='State')\n",
    "\n",
    "\n",
    "# Select and sort columns\n",
    "demographic = df_demo[['State','State Code',\n",
    "                       'Count',\n",
    "                       'Median Age',\n",
    "                       'Male Population',\n",
    "                       'Female Population',\n",
    "                       'Number of Veterans',\n",
    "                       'Foreign-born',\n",
    "                       'Average Household Size',\n",
    "                       'American Indian and Alaska Native',\n",
    "                       'Asian','Black or African-American',\n",
    "                       'Hispanic or Latino',\n",
    "                       'White']].sort_values('State')\n",
    "demographic = demographic.rename(columns={'State': 'state', \n",
    "                                          'State Code':'state_code',\n",
    "                                          'Count':'population',\n",
    "                                          'Median Age':'median_age',\n",
    "                                          'Male Population':'male_population',\n",
    "                                          'Female Population':'female_population',\n",
    "                                          'Number of Veterans':'number_of_veterans',\n",
    "                                          'Foreign-born':'foreign_born',\n",
    "                                          'Average Household Size':'average_household_size',\n",
    "                                          'American Indian and Alaska Native':'AmericanIndian_and_AlaskaNative_population',\n",
    "                                          'Asian':'Asian_population',\n",
    "                                          'Black or African-American':'Black_or_AfricanAmerican_population',\n",
    "                                          'Hispanic or Latino':'Hispanic_or_Latino_population',\n",
    "                                          'White':'White_population'})\n",
    "# Replace null value by 0\n",
    "demographic = demographic.fillna(0)\n",
    "\n",
    "demographic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>county</th>\n",
       "      <th>state</th>\n",
       "      <th>category</th>\n",
       "      <th>total_crime</th>\n",
       "      <th>violent_crime</th>\n",
       "      <th>murder_and_nonnegligent_manslaughter</th>\n",
       "      <th>robbery</th>\n",
       "      <th>aggravated_assault</th>\n",
       "      <th>property_crime</th>\n",
       "      <th>burglary</th>\n",
       "      <th>larceny-theft</th>\n",
       "      <th>motor_vehicle_theft</th>\n",
       "      <th>arson3</th>\n",
       "      <th>rape</th>\n",
       "      <th>crime_rate</th>\n",
       "      <th>violent_crime_rate</th>\n",
       "      <th>property_crime_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Autauga</td>\n",
       "      <td>ALABAMA</td>\n",
       "      <td>Metropolitan Counties</td>\n",
       "      <td>419</td>\n",
       "      <td>69</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>50</td>\n",
       "      <td>344</td>\n",
       "      <td>111</td>\n",
       "      <td>187</td>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>972.5</td>\n",
       "      <td>160.1</td>\n",
       "      <td>798.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Baldwin</td>\n",
       "      <td>ALABAMA</td>\n",
       "      <td>Metropolitan Counties</td>\n",
       "      <td>796</td>\n",
       "      <td>115</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>73</td>\n",
       "      <td>648</td>\n",
       "      <td>225</td>\n",
       "      <td>390</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>406.1</td>\n",
       "      <td>58.7</td>\n",
       "      <td>330.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bibb</td>\n",
       "      <td>ALABAMA</td>\n",
       "      <td>Metropolitan Counties</td>\n",
       "      <td>49</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>41</td>\n",
       "      <td>20</td>\n",
       "      <td>18</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>366.6</td>\n",
       "      <td>52.4</td>\n",
       "      <td>306.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Blount</td>\n",
       "      <td>ALABAMA</td>\n",
       "      <td>Metropolitan Counties</td>\n",
       "      <td>1046</td>\n",
       "      <td>204</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>178</td>\n",
       "      <td>832</td>\n",
       "      <td>247</td>\n",
       "      <td>503</td>\n",
       "      <td>82</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>5878.7</td>\n",
       "      <td>1146.5</td>\n",
       "      <td>4676.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Calhoun</td>\n",
       "      <td>ALABAMA</td>\n",
       "      <td>Metropolitan Counties</td>\n",
       "      <td>430</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>413</td>\n",
       "      <td>181</td>\n",
       "      <td>225</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>309.1</td>\n",
       "      <td>11.5</td>\n",
       "      <td>296.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    county    state                category  total_crime  violent_crime  \\\n",
       "0  Autauga  ALABAMA   Metropolitan Counties          419             69   \n",
       "1  Baldwin  ALABAMA   Metropolitan Counties          796            115   \n",
       "2     Bibb  ALABAMA   Metropolitan Counties           49              7   \n",
       "3   Blount  ALABAMA   Metropolitan Counties         1046            204   \n",
       "4  Calhoun  ALABAMA   Metropolitan Counties          430             16   \n",
       "\n",
       "   murder_and_nonnegligent_manslaughter  robbery  aggravated_assault  \\\n",
       "0                                     0        6                  50   \n",
       "1                                     0       33                  73   \n",
       "2                                     0        1                   4   \n",
       "3                                     5        5                 178   \n",
       "4                                     0        1                  11   \n",
       "\n",
       "   property_crime  burglary  larceny-theft  motor_vehicle_theft  arson3  rape  \\\n",
       "0             344       111            187                   46       0    13   \n",
       "1             648       225            390                   33       0     9   \n",
       "2              41        20             18                    3       0     2   \n",
       "3             832       247            503                   82       0    16   \n",
       "4             413       181            225                    7       0     4   \n",
       "\n",
       "   crime_rate  violent_crime_rate  property_crime_rate  \n",
       "0       972.5               160.1                798.4  \n",
       "1       406.1                58.7                330.6  \n",
       "2       366.6                52.4                306.8  \n",
       "3      5878.7              1146.5               4676.0  \n",
       "4       309.1                11.5                296.9  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cleaning and aggregating Crime table\n",
    "\n",
    "# Split a column which has more than 1 elements into separate columns\n",
    "state = df_crime[\"State\"].str.split(\"-\",expand = True) \n",
    "df_crime[\"State\"] = state[0]\n",
    "df_crime[\"category\"] = state[1]\n",
    "\n",
    "# Change data types of each column\n",
    "df_crime = df_crime.fillna(0)\n",
    "df_crime = df_crime.astype({'Rape_1': int, \n",
    "                            'Rape_2': int, \n",
    "                            'Property_crime': int,\n",
    "                            'Burglary':int, \n",
    "                            'Larceny-theft':int, \n",
    "                            'Motor_vehicle_theft':int, \n",
    "                            'Arson3':int})\n",
    "\n",
    "# Sum up some of the column values to simplify the table. Also get a total value for all crime numbers\n",
    "df_crime['Rape'] = df_crime['Rape_1'] + df_crime['Rape_2']\n",
    "df_crime = df_crime.drop(['Rape_1', \n",
    "                          'Rape_2'], axis=1)\n",
    "df_crime['total_crime'] = df_crime['Violent_crime']\\\n",
    "+ df_crime['Murder_and_nonnegligent_manslaughter']\\\n",
    "+ df_crime['Robbery']\\\n",
    "+ df_crime['Burglary']\\\n",
    "+ df_crime['Larceny-theft']\\\n",
    "+ df_crime['Motor_vehicle_theft']\\\n",
    "+ df_crime['Arson3']\n",
    "\n",
    "# Cleaning County names and sum up\n",
    "df_crime['State'] = df_crime['State'].str.strip()\n",
    "df_crime['County'] = [re.sub(r'\\d+|\\,','', x) for x in df_crime['County']]\n",
    "df_crime['County_fixed'] = df_crime['County']\\\n",
    ".replace('Police| Department| Unified| County| Public Safety', \"\", regex=True)\n",
    "df_crime['County_fixed'] = df_crime['County_fixed'].str.strip()\n",
    "\n",
    "# Join US Demographic table and Crime table to get total population of states.\n",
    "df_label['county_new'] = df_label['county_name']\\\n",
    ".mask((df_label['county_name']=='LaSalle') & (df_label['state_name']=='Illinois'), \n",
    "      'La Salle')\\\n",
    ".mask((df_label['county_name']=='LaPorte') & (df_label['state_name']=='Indiana'), \n",
    "      'La Porte')\\\n",
    ".mask((df_label['county_name']=='DeKalb') & (df_label['state_name']=='Indiana'), \n",
    "      'De Kalb')\\\n",
    ".mask((df_label['county_name']=='LaSalle') & (df_label['state_name']=='Louisiana'), \n",
    "      'La Salle')\\\n",
    ".mask((df_label['county_name']=='Lac qui Parle') & (df_label['state_name']=='Minnesota'), \n",
    "      'Lac Qui Parle')\\\n",
    ".mask((df_label['county_name']=='Trousdale') & (df_label['state_name']=='Tennessee'), \n",
    "      'Hartsville/Trousdale')\\\n",
    ".mask((df_label['county_name']=='Doña Ana') & (df_label['state_name']=='New Mexico'), \n",
    "      'Dona Ana')\\\n",
    ".mask((df_label['county_name']=='Dutchess') & (df_label['state_name']=='New York'), \n",
    "      'Duchess')\\\n",
    ".mask((df_label['county_name']=='LaMoure') & (df_label['state_name']=='North Dakota'), \n",
    "      'Lamoure')\n",
    "df_label_for_join = df_label[['state_name',\n",
    "                              'county_new',\n",
    "                              'population']]\n",
    "df_label_for_join = pd.DataFrame(df_label_for_join.groupby(['state_name',\n",
    "                                                            'county_new'])\\\n",
    "                                 .agg({'population':'sum'})).reset_index()\n",
    "df_label_for_join['state_name'] = df_label_for_join['state_name'].str.upper()\n",
    "\n",
    "# Join population column from demographic table to crime table and calculate crime rate\n",
    "crime = pd.merge(df_crime, \n",
    "                 df_label_for_join, \n",
    "                 left_on=['State','County_fixed'], \n",
    "                 right_on=['state_name','county_new'], \n",
    "                 how='inner')\n",
    "crime['crime_rate'] = (crime['total_crime']/crime['population']*100000)\\\n",
    ".astype(float).round(1)\n",
    "crime['violent_crime_rate'] = (crime['Violent_crime']/crime['population']*100000)\\\n",
    ".astype(float).round(1)\n",
    "crime['property_crime_rate'] = (crime['Property_crime']/crime['population']*100000)\\\n",
    ".astype(float).round(1)\n",
    "crime['population'] = crime['population'].astype(int)\n",
    "crime = crime[['County_fixed',\n",
    "               'State','category',\n",
    "               'total_crime',\n",
    "               'Violent_crime',\n",
    "               'Murder_and_nonnegligent_manslaughter',\n",
    "               'Robbery','Aggravated_assault',\n",
    "               'Property_crime',\n",
    "               'Burglary',\n",
    "               'Larceny-theft',\n",
    "               'Motor_vehicle_theft',\n",
    "               'Arson3',\n",
    "               'Rape',\n",
    "               'crime_rate',\n",
    "               'violent_crime_rate',\n",
    "               'property_crime_rate']]\n",
    "crime = crime.rename(columns={'County_fixed':'county',\n",
    "                              'State':'state',\n",
    "                              'Violent_crime':'violent_crime',\n",
    "                              'Murder_and_nonnegligent_manslaughter':'murder_and_nonnegligent_manslaughter',\n",
    "                              'Robbery':'robbery',\n",
    "                              'Aggravated_assault':'aggravated_assault',\n",
    "                              'Property_crime':'property_crime',\n",
    "                              'Burglary':'burglary',\n",
    "                              'Larceny-theft':'larceny-theft',\n",
    "                              'Motor_vehicle_theft':'motor_vehicle_theft',\n",
    "                              'Arson3':'arson3',\n",
    "                              'Rape':'rape'})\n",
    "crime.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check number of null values in each column for data cleaning\n",
    "#immigration_data.select([count(when(col(c).isNull(), c)).alias(c) for c in immigration_data.columns]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning Immigration table\n",
    "\n",
    "def convert_datetime(x):\n",
    "    \"\"\"a function to convert integer to date format\"\"\"\n",
    "    try:\n",
    "        start = datetime(1960, 1, 1)\n",
    "        return start + timedelta(days=int(x))\n",
    "    except:\n",
    "        return None\n",
    "udf_datetime_from_sas = udf(lambda x: convert_datetime(x), T.DateType())\n",
    "\n",
    "# For those columns that have many missing values or that are not important for this project, deleted them, \n",
    "# change column data types, and rename column names to make it more understandable\n",
    "immigration_data = immigration_data.drop(\"i94mode\")\\\n",
    ".drop('occup')\\\n",
    ".drop('entdepu')\\\n",
    ".drop(\"insnum\")\\\n",
    ".drop('entdepa')\\\n",
    ".drop('matflag')\\\n",
    ".drop('count')\\\n",
    ".drop('visatype')\\\n",
    ".drop('visapost')\\\n",
    ".drop('entdepd')\\\n",
    ".drop('year')\\\n",
    ".drop('month')\\\n",
    ".withColumn(\"id\", col(\"cicid\").cast(\"integer\")) \\\n",
    ".drop(\"cicid\") \\\n",
    ".withColumn(\"year\", col(\"i94yr\").cast(\"integer\")) \\\n",
    ".drop(\"i94yr\") \\\n",
    ".withColumn(\"month\", col(\"i94mon\").cast(\"integer\")) \\\n",
    ".drop(\"i94mon\") \\\n",
    ".withColumn(\"origin_country\", col(\"i94cit\").cast(\"bigint\")) \\\n",
    ".drop(\"i94cit\") \\\n",
    ".withColumn(\"resident_country\", col(\"i94res\").cast(\"bigint\")) \\\n",
    ".drop(\"i94res\") \\\n",
    ".withColumnRenamed(\"i94port\", \"port_of_entry\")\\\n",
    ".withColumnRenamed(\"i94addr\", \"state_code\")\\\n",
    ".withColumn(\"birth_year\", col(\"biryear\").cast(\"integer\")) \\\n",
    ".drop(\"biryear\") \\\n",
    ".withColumn(\"visa_type\", col(\"i94visa\").cast(\"bigint\")) \\\n",
    ".drop(\"i94visa\") \\\n",
    ".withColumn(\"age\", col(\"i94bir\").cast(\"integer\")) \\\n",
    ".drop(\"i94bir\") \\\n",
    ".withColumn(\"admission_no\", col(\"admnum\").cast(\"integer\")) \\\n",
    ".drop(\"admnum\") \\\n",
    ".withColumnRenamed(\"fltno\", \"flight_no\")\\\n",
    ".withColumn('admitted_date',F.to_date(F.unix_timestamp(immigration_data.dtaddto, 'MMddyyyy').cast('timestamp')))\\\n",
    ".drop(\"dtaddto\")\\\n",
    ".withColumn('created_date',F.to_date(F.unix_timestamp(immigration_data.dtadfile, 'yyyyMMdd').cast('timestamp')))\\\n",
    ".drop(\"dtadfile\")\\\n",
    ".withColumn(\"departure_date\", udf_datetime_from_sas(\"depdate\"))\\\n",
    ".drop(\"depdate\")\\\n",
    ".withColumn(\"arrival_date\", udf_datetime_from_sas(\"arrdate\"))\\\n",
    ".drop(\"arrdate\")\n",
    "\n",
    "# Delete null values\n",
    "immigration_data = immigration_data.dropna(\"any\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(id=1973857, created_date=datetime.date(2016, 4, 11), admission_no=2147483647, admitted_date=datetime.date(2016, 7, 9), departure_date=datetime.date(2016, 4, 25), arrival_date=datetime.date(2016, 4, 11), port_name='NEWARK/TETERBORO', airport_name='Lakefront Airport', entry_state_id='LA', entry_state_name='LOUISIANA', entry_county='New Orleans', airline='UA', flight_no='00998', gender='F', birth_year=1990, age=26, origin_country_name='BELGIUM', resident_country_name='BELGIUM', visa_type=2, visa_type_name='Pleasure', state_code='AZ', current_state_name='ARIZONA'),\n",
       " Row(id=3700217, created_date=datetime.date(2016, 4, 20), admission_no=2147483647, admitted_date=datetime.date(2016, 10, 19), departure_date=datetime.date(2016, 5, 22), arrival_date=datetime.date(2016, 4, 20), port_name='NEWARK/TETERBORO', airport_name='Lakefront Airport', entry_state_id='LA', entry_state_name='LOUISIANA', entry_county='New Orleans', airline='UA', flight_no='00961', gender='M', birth_year=1981, age=35, origin_country_name='INDIA', resident_country_name='INDIA', visa_type=1, visa_type_name='Business', state_code='SC', current_state_name='SOUTH CAROLINA'),\n",
       " Row(id=641170, created_date=datetime.date(2016, 4, 4), admission_no=2147483647, admitted_date=datetime.date(2016, 7, 2), departure_date=datetime.date(2016, 4, 7), arrival_date=datetime.date(2016, 4, 4), port_name='NEWARK/TETERBORO', airport_name='Lakefront Airport', entry_state_id='LA', entry_state_name='LOUISIANA', entry_county='New Orleans', airline='LH', flight_no='00402', gender='M', birth_year=1966, age=50, origin_country_name='ITALY', resident_country_name='ITALY', visa_type=1, visa_type_name='Business', state_code='SC', current_state_name='SOUTH CAROLINA'),\n",
       " Row(id=4280680, created_date=datetime.date(2016, 4, 23), admission_no=2147483647, admitted_date=datetime.date(2016, 7, 21), departure_date=datetime.date(2016, 4, 30), arrival_date=datetime.date(2016, 4, 23), port_name='NEWARK/TETERBORO', airport_name='Lakefront Airport', entry_state_id='LA', entry_state_name='LOUISIANA', entry_county='New Orleans', airline='BA', flight_no='00185', gender='M', birth_year=1958, age=58, origin_country_name='SWITZERLAND', resident_country_name='SWITZERLAND', visa_type=2, visa_type_name='Pleasure', state_code='SC', current_state_name='SOUTH CAROLINA'),\n",
       " Row(id=3892965, created_date=datetime.date(2016, 4, 21), admission_no=2147483647, admitted_date=datetime.date(2016, 10, 20), departure_date=datetime.date(2016, 9, 10), arrival_date=datetime.date(2016, 4, 21), port_name='NEWARK/TETERBORO', airport_name='Lakefront Airport', entry_state_id='LA', entry_state_name='LOUISIANA', entry_county='New Orleans', airline='UA', flight_no='00180', gender='F', birth_year=1960, age=56, origin_country_name='CHINA', resident_country_name='CHINA', visa_type=2, visa_type_name='Pleasure', state_code='SC', current_state_name='SOUTH CAROLINA')]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# In order to add label columns from other tables to Immigration table for acquiring code lables, format I94_SAS_Labels_Descriptions.SAS and uscities.csv file to join\n",
    "sqlContext = SQLContext(spark)\n",
    "\n",
    "def equivalent_type(f):\n",
    "    if f == 'datetime64[ns]': return TimestampType()\n",
    "    elif f == 'int64': return LongType()\n",
    "    elif f == 'int32': return IntegerType()\n",
    "    elif f == 'float64': return FloatType()\n",
    "    else: return StringType()\n",
    "\n",
    "def define_structure(string, format_type):\n",
    "    try: typo = equivalent_type(format_type)\n",
    "    except: typo = StringType()\n",
    "    return StructField(string, typo)\n",
    "\n",
    "def pandas_to_spark(pandas_df):\n",
    "    columns = list(pandas_df.columns)\n",
    "    types = list(pandas_df.dtypes)\n",
    "    struct_list = []\n",
    "    for column, typo in zip(columns, types): \n",
    "        struct_list.append(define_structure(column, typo))\n",
    "    p_schema = StructType(struct_list)\n",
    "    return sqlContext.createDataFrame(pandas_df, p_schema)\n",
    "\n",
    "# Open and read a text file\n",
    "with open(\"./I94_SAS_Labels_Descriptions.SAS\") as f:\n",
    "    textfile = f.readlines()\n",
    "    \n",
    "# Create and format label tables for ports, countries, and visa\n",
    "def process_text_file(file):\n",
    "    \"\"\"Convert text file into a dataframe format\"\"\"\n",
    "    df = list(map(lambda x:x.strip(),file))\n",
    "    df = [re.sub(r'\\t','', x) for x in df]\n",
    "    df = [x.replace('=',',') for x in df]\n",
    "    df = [x.replace('\\'','') for x in df]\n",
    "    df = pd.DataFrame(df)\n",
    "    df = df[0].str.split(\",\",expand = True)\n",
    "    df[0] = df[0].str.strip()\n",
    "    df[1] = df[1].str.strip()\n",
    "    return df[[0,1]]\n",
    "\n",
    "ports = textfile[302:962]\n",
    "df_ports = process_text_file(ports)\n",
    "df_ports = df_ports.rename(columns={0: 'entry_port_code', \n",
    "                                    1: 'port_name'})\n",
    "\n",
    "countries = textfile[10:298]\n",
    "df_countries = process_text_file(countries)\n",
    "df_countries[0] = df_countries[0].astype(int)\n",
    "df_countries_origin = df_countries.rename(columns={0: 'country_code', \n",
    "                                                   1: 'origin_country_name'})\n",
    "df_countries_resident = df_countries.rename(columns={0: 'country_code', \n",
    "                                                     1: 'resident_country_name'})\n",
    "\n",
    "visa = textfile[1046:1049]\n",
    "df_visa = process_text_file(visa)\n",
    "df_visa[0] = df_visa[0].astype(int)\n",
    "df_visa = df_visa.rename(columns={0: 'visa_type_code', \n",
    "                                  1: 'visa_type_name'})\n",
    "\n",
    "# Format df_label table to join state names\n",
    "df_label_state = df_label[['state_name',\n",
    "                           'city',\n",
    "                           'state_id',\n",
    "                           'county_name']]\n",
    "df_label_state = pd.DataFrame(df_label_state\n",
    "                              .groupby(['state_id'])\n",
    "                              .agg({'state_name':'max'})).reset_index()\n",
    "df_label_state['state_name'] = df_label_state['state_name'].str.upper().str.strip()\n",
    "df_label_current = df_label_state.rename(columns={'state_name': 'current_state_name'})\n",
    "df_label_entry = df_label_state.rename(columns={'state_name': 'entry_state_name'})\n",
    "\n",
    "# Convert pandas dataframes to pyspark dataframes for joining with Immigration table\n",
    "dfs = [df_ports, \n",
    "       df_countries_origin, \n",
    "       df_countries_resident, \n",
    "       df_visa, df_airport, \n",
    "       df_label_current, \n",
    "       df_label_entry]\n",
    "dfs_new = [pandas_to_spark(file) for file in dfs]\n",
    "df_ports_for_join, \\\n",
    "df_countries_origin_for_join, \\\n",
    "df_countries_resident_for_join, \\\n",
    "df_visa_for_join, \\\n",
    "df_airport_for_join, \\\n",
    "df_label_current_for_join, \\\n",
    "df_label_entry_for_join = dfs_new\n",
    "\n",
    "# Join converted dataframes with Immigration table to add columns\n",
    "immigration_data = immigration_data.join(df_ports_for_join, \n",
    "                                         immigration_data.port_of_entry == df_ports_for_join.entry_port_code, \n",
    "                                         \"left\")\n",
    "immigration_data = immigration_data.join(df_countries_origin_for_join, \n",
    "                                         immigration_data.origin_country == df_countries_origin_for_join.country_code, \n",
    "                                         \"left\")\n",
    "immigration_data = immigration_data.join(df_countries_resident_for_join, \n",
    "                                         immigration_data.resident_country == df_countries_resident_for_join.country_code, \n",
    "                                         \"left\")\n",
    "immigration_data = immigration_data.join(df_visa_for_join, \n",
    "                                         immigration_data.visa_type == df_visa_for_join.visa_type_code, \n",
    "                                         \"left\")\n",
    "immigration_data = immigration_data.join(df_airport_for_join, \n",
    "                                         immigration_data.port_of_entry == df_airport_for_join.local_code, \n",
    "                                         \"left\")\n",
    "immigration_data = immigration_data.join(df_label_current_for_join, \n",
    "                                         immigration_data.state_code == df_label_current_for_join.state_id, \n",
    "                                         \"left\")\n",
    "immigration_data = immigration_data.join(df_label_entry_for_join, \n",
    "                                         immigration_data.entry_state_id == df_label_entry_for_join.state_id, \n",
    "                                         \"left\")\n",
    "\n",
    "# Select and sort columns\n",
    "immigration_data = immigration_data.drop(\"country_code\")\\\n",
    ".drop('origin_country')\\\n",
    ".drop('resident_country')\\\n",
    ".drop(\"entry_port_code\")\\\n",
    ".drop(\"visa_type_code\")\\\n",
    ".drop(\"local_code\")\\\n",
    ".drop(\"state_id\")\n",
    "\n",
    "immigration = immigration_data.select(\"id\",\n",
    "                                      \"created_date\",\n",
    "                                      \"admission_no\",\n",
    "                                      \"admitted_date\",\n",
    "                                      \"departure_date\",\n",
    "                                      \"arrival_date\",\n",
    "                                      \"port_name\",\n",
    "                                      \"airport_name\",\n",
    "                                      \"entry_state_id\",\n",
    "                                      \"entry_state_name\",\n",
    "                                      \"entry_county\",\n",
    "                                      \"airline\",\n",
    "                                      \"flight_no\",\n",
    "                                      \"gender\",\n",
    "                                      \"birth_year\",\n",
    "                                      \"age\",\n",
    "                                      \"origin_country_name\",\n",
    "                                      \"resident_country_name\",\n",
    "                                      \"visa_type\",\n",
    "                                      \"visa_type_name\",\n",
    "                                      \"state_code\",\n",
    "                                      'current_state_name')\n",
    "\n",
    "# Shrink data into sample rows for the sake of a learning project -- this row should be filtered out in actual environment\n",
    "immigration = spark.createDataFrame(immigration.sample(0.01).collect())\n",
    "\n",
    "immigration.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+---+----+-----+----+-------+\n",
      "|created_date|day|week|month|year|weekday|\n",
      "+------------+---+----+-----+----+-------+\n",
      "|  2016-06-23| 23|  25|    6|2016|      5|\n",
      "|  2016-04-14| 14|  15|    4|2016|      5|\n",
      "|  2016-05-24| 24|  21|    5|2016|      3|\n",
      "|  2016-05-26| 26|  21|    5|2016|      5|\n",
      "|  2016-05-03|  3|  18|    5|2016|      3|\n",
      "+------------+---+----+-----+----+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Creating Date table using Immigration table\n",
    "\n",
    "date = immigration_data.withColumn(\"day\", dayofmonth(\"created_date\")) \\\n",
    "        .withColumn(\"week\", weekofyear(\"created_date\")) \\\n",
    "        .withColumn(\"month\", month(\"created_date\")) \\\n",
    "        .withColumn(\"year\", year(\"created_date\")) \\\n",
    "        .withColumn(\"weekday\", dayofweek(\"created_date\"))\\\n",
    "    .select(\"created_date\", \n",
    "            \"day\", \n",
    "            \"week\", \n",
    "            \"month\", \n",
    "            \"year\", \n",
    "            \"weekday\").drop_duplicates()\n",
    "date.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>county</th>\n",
       "      <th>state</th>\n",
       "      <th>avg_temperature</th>\n",
       "      <th>max_of_monthly_avg_temperature</th>\n",
       "      <th>min_of_monthly_avg_temperature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Allegheny</td>\n",
       "      <td>PENNSYLVANIA</td>\n",
       "      <td>9.61</td>\n",
       "      <td>28.60</td>\n",
       "      <td>-11.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Allen</td>\n",
       "      <td>INDIANA</td>\n",
       "      <td>9.70</td>\n",
       "      <td>29.04</td>\n",
       "      <td>-12.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bell</td>\n",
       "      <td>TEXAS</td>\n",
       "      <td>18.54</td>\n",
       "      <td>32.66</td>\n",
       "      <td>1.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bernalillo</td>\n",
       "      <td>NEW MEXICO</td>\n",
       "      <td>11.14</td>\n",
       "      <td>25.69</td>\n",
       "      <td>-5.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Broward</td>\n",
       "      <td>FLORIDA</td>\n",
       "      <td>23.07</td>\n",
       "      <td>30.13</td>\n",
       "      <td>12.96</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       county         state  avg_temperature  max_of_monthly_avg_temperature  \\\n",
       "0   Allegheny  PENNSYLVANIA             9.61                           28.60   \n",
       "1       Allen       INDIANA             9.70                           29.04   \n",
       "2        Bell         TEXAS            18.54                           32.66   \n",
       "3  Bernalillo    NEW MEXICO            11.14                           25.69   \n",
       "4     Broward       FLORIDA            23.07                           30.13   \n",
       "\n",
       "   min_of_monthly_avg_temperature  \n",
       "0                          -11.42  \n",
       "1                          -12.44  \n",
       "2                            1.67  \n",
       "3                           -5.07  \n",
       "4                           12.96  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cleaning and aggregating Temperature table\n",
    "\n",
    "# Format df_label table to join with temperature table\n",
    "df_county = pd.DataFrame(df_label\n",
    "                         .groupby(['city'])\n",
    "                         .agg({'county_name':'max',\n",
    "                               'state_name':'max'})).reset_index()\n",
    "\n",
    "# Delete rows with null values, filter with only US data\n",
    "df_temp = df_temp.dropna()\n",
    "df_temp['dt'] = pd.to_datetime(df_temp['dt'])\n",
    "df_temp = df_temp[df_temp['Country']=='United States']\n",
    "\n",
    "# Aggregate table to get avg, min, and max value of temperature for each city\n",
    "df_temp_mean = pd.DataFrame(df_temp\n",
    "                            .groupby(['City'])\n",
    "                            .agg({'AverageTemperature':'mean'})).reset_index()\n",
    "df_temp_mean = df_temp_mean.rename(columns = {'AverageTemperature':'avg_temperature'})\n",
    "df_temp_mean['avg_temperature'] = df_temp_mean['avg_temperature'].round(2)\n",
    "df_temp_max = pd.DataFrame(df_temp\n",
    "                           .groupby(['City'])\n",
    "                           .agg({'AverageTemperature':'max'})).reset_index()\n",
    "df_temp_max = df_temp_max.rename(columns = {'AverageTemperature':'max_of_monthly_avg_temperature'})\n",
    "df_temp_max['max_of_monthly_avg_temperature'] = df_temp_max['max_of_monthly_avg_temperature'].round(2)\n",
    "df_temp_min = pd.DataFrame(df_temp\n",
    "                           .groupby(['City'])\n",
    "                           .agg({'AverageTemperature':'min'})).reset_index()\n",
    "df_temp_min = df_temp_min.rename(columns = {'AverageTemperature':'min_of_monthly_avg_temperature'})\n",
    "df_temp_min['min_of_monthly_avg_temperature'] = df_temp_min['min_of_monthly_avg_temperature'].round(2)\n",
    "mean_max = pd.merge(df_temp_mean,df_temp_max)\n",
    "mean_max_min = pd.merge(mean_max,df_temp_min)\n",
    "\n",
    "# Join with df_county table to add county column\n",
    "temp = pd.merge(mean_max_min, \n",
    "                df_county, \n",
    "                left_on='City', \n",
    "                right_on='city', \n",
    "                how='inner')\n",
    "temp = temp.groupby(['county_name',\n",
    "                     'state_name'])\\\n",
    ".agg({'avg_temperature':'mean',\n",
    "      'max_of_monthly_avg_temperature':'max',\n",
    "      'min_of_monthly_avg_temperature':'min'}).reset_index()\n",
    "\n",
    "# Select and sort columns\n",
    "temperature = temp[['county_name', \n",
    "                    'state_name',\n",
    "                    'avg_temperature', \n",
    "                    'max_of_monthly_avg_temperature', \n",
    "                    'min_of_monthly_avg_temperature']].sort_values('county_name')\n",
    "temperature['state_name'] = temperature['state_name'].str.upper()\n",
    "temperature = temperature.rename(columns={'county_name':'county',\n",
    "                                          'state_name':'state'})\n",
    "temperature.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Define the Data Model\n",
    "#### 3.1 Conceptual Data Model\n",
    "#### Tables:\n",
    "##### Fact Table:  \n",
    "###### 1. immigration\n",
    " - description: contains i94 immigrations data\n",
    " - columns: *id, created_date, year, month, admission_no, admitted_date, departure_date, arrival_date, port_name, airport_name, entry_state_id, entry_state_name, entry_county, airline, flight_no, gender, birth_year, age, origin_country_name, resident_country_name, visa_type, visa_type_name, state_code, current_state_name*\n",
    " \n",
    "##### Dimension Tables:  \n",
    "\n",
    "###### 2. demographic\n",
    " - description:  contains demographic information by US cities\n",
    " - columns:  *State(Primary key), State Code, City, Count, Race, Median Age, Male Population, Female Population, Number of Veterans, Foreign-born, Average Household Size*\n",
    " \n",
    "###### 3. crime\n",
    " - description: contains crime information in different categories by US states\n",
    " - columns:  *county(Composite key), state(Composite key), category, total_crime, Violent_crime, Murder_and_nonnegligent_manslaughter, Robbery, Aggravated_assault, Property_crime, Burglary, Larceny-theft, Motor_vehicle_theft, Arson3, Rape, crime_rate, violent_crime_rate, property_crime_rate*\n",
    " \n",
    "###### 4. temperature\n",
    " - description:  contains temperatures by US counties\n",
    " - columns:  *county(Composite key), state(Composite key), avg_temperature, max_of_monthly_avg_temperature, min_of_monthly_avg_temperature*\n",
    " \n",
    "###### 5. date\n",
    " - description:  contains date information related to Immigration table\n",
    " - columns:  *created_date(Primary key), day, week, month, year, weekday*\n",
    "\n",
    "##### Why I chose this model:\n",
    "Along with Immigration table which contains key information about each immigrant in the US, I provided with a variety of dimension tables that could be useful for exploring immigration table more in details.\n",
    "To do so, I have transformed all tables in a way that one can join them with immigration table by cleaning fact table to make foreign keys and by setting primary keys in each dimension table.\n",
    "\n",
    "\n",
    "#### 3.2 Mapping Out Data Pipelines\n",
    "List the steps necessary to pipeline the data into the chosen data model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run 'create_tables.py'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define connecion and curser\n",
    "conn = psycopg2.connect(\"host=127.0.0.1 dbname=immigrationdb user=student password=student\")\n",
    "cur = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert pyspark tables to pandas dataframes\n",
    "immigration = immigration.toPandas()\n",
    "date = date.toPandas()\n",
    "\n",
    "# Insert data into created tables\n",
    "for index, row in demographic.iterrows():\n",
    "    cur.execute(demographic_table_insert, list(row.values))\n",
    "    conn.commit()\n",
    "\n",
    "for index, row in immigration.iterrows():\n",
    "    cur.execute(immigration_table_insert, list(row.values))\n",
    "    conn.commit()\n",
    "    \n",
    "for index, row in crime.iterrows():\n",
    "    cur.execute(crime_table_insert, list(row.values))\n",
    "    conn.commit()\n",
    "    \n",
    "for index, row in date.iterrows():\n",
    "    cur.execute(date_table_insert, list(row.values))\n",
    "    conn.commit()\n",
    "    \n",
    "for index, row in temperature.iterrows():\n",
    "    cur.execute(temperature_table_insert, list(row.values))\n",
    "    conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Run Pipelines to Model the Data \n",
    "#### 4.1 Create the data model\n",
    "1. Create database and tables by running *'create_tables.py'* file\n",
    "2. Extract, transform, and load data by running *'etl.py'* file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2 Data Quality Checks\n",
    "Explain the data quality checks you'll perform to ensure the pipeline ran as expected. These could include:\n",
    " * Integrity constraints on the relational database (e.g., unique key, data type, etc.)\n",
    " * Unit tests for the scripts to ensure they are doing the right thing\n",
    " * Source/Count checks to ensure completeness\n",
    " \n",
    "Run Quality Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "immigration_table_check: SQL Tests Passed\n",
      "demographic_table_check: SQL Tests Passed\n",
      "crime_table_check: SQL Tests Passed\n",
      "date_table_check: SQL Tests Passed\n",
      "temperature_table_check: SQL Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def data_check(cur, conn):\n",
    "    \"\"\" \n",
    "    This data checks tables which data was inserted into to make sure they contain values,\n",
    "    and raising error messages if they have no results or cantain no rows.\n",
    "    \"\"\"\n",
    "    failing_tests = []\n",
    "    for key in data_check_queries:\n",
    "        cur.execute(data_check_queries[key])\n",
    "        sql_result = cur.fetchone()\n",
    "        \n",
    "        exp_result = 0\n",
    "        \n",
    "        error_count = 0\n",
    "        \n",
    "        if exp_result != sql_result [0]:\n",
    "            error_count += 1\n",
    "            failing_tests.append(data_check_queries[key])\n",
    "            \n",
    "        if error_count > 0:\n",
    "            print(f'{key}: SQL Tests Failed')\n",
    "            raise ValueError('Data quality check failed')\n",
    "            \n",
    "        if error_count == 0:\n",
    "            print(f'{key}: SQL Tests Passed') \n",
    "            \n",
    "data_check(cur, conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49, 14)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demographic.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "state                                         0\n",
       "state_code                                    0\n",
       "population                                    0\n",
       "median_age                                    0\n",
       "male_population                               0\n",
       "female_population                             0\n",
       "number_of_veterans                            0\n",
       "foreign_born                                  0\n",
       "average_household_size                        0\n",
       "AmericanIndian_and_AlaskaNative_population    0\n",
       "Asian_population                              0\n",
       "Black_or_AfricanAmerican_population           0\n",
       "Hispanic_or_Latino_population                 0\n",
       "White_population                              0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demographic.isnull().sum(axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sql extension is already loaded. To reload it, use:\n",
      "  %reload_ext sql\n",
      " * postgresql://student:***@127.0.0.1/immigrationdb\n",
      "1 rows affected.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr>\n",
       "        <th>state_null_count</th>\n",
       "        <th>state_code_null_count</th>\n",
       "        <th>population_null_count</th>\n",
       "        <th>median_age_null_count</th>\n",
       "        <th>male_population_null_count</th>\n",
       "        <th>female_population_null_count</th>\n",
       "        <th>number_of_veterans_null_count</th>\n",
       "        <th>foreign_born_null_count</th>\n",
       "        <th>average_household_size_null_count</th>\n",
       "        <th>americanindian_and_alaskanative_population_null_count</th>\n",
       "        <th>asian_population_null_count</th>\n",
       "        <th>black_or_africanamerican_population_null_count</th>\n",
       "        <th>hispanic_or_latino_population_null_count</th>\n",
       "        <th>white_population_null_count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>0</td>\n",
       "        <td>0</td>\n",
       "        <td>0</td>\n",
       "        <td>0</td>\n",
       "        <td>0</td>\n",
       "        <td>0</td>\n",
       "        <td>0</td>\n",
       "        <td>0</td>\n",
       "        <td>0</td>\n",
       "        <td>0</td>\n",
       "        <td>0</td>\n",
       "        <td>0</td>\n",
       "        <td>0</td>\n",
       "        <td>0</td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "[(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0)]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%load_ext sql\n",
    "%sql postgresql://student:student@127.0.0.1/immigrationdb\n",
    "\n",
    "%sql SELECT \\\n",
    "sum(case when state is null then 1 else 0 end) as state_null_count, \\\n",
    "sum(case when state_code is null then 1 else 0 end) as state_code_null_count,\\\n",
    "sum(case when population is null then 1 else 0 end) as population_null_count, \\\n",
    "sum(case when median_age is null then 1 else 0 end) as median_age_null_count, \\\n",
    "sum(case when male_population is null then 1 else 0 end) as male_population_null_count, \\\n",
    "sum(case when female_population is null then 1 else 0 end) as female_population_null_count, \\\n",
    "sum(case when number_of_veterans is null then 1 else 0 end) as number_of_veterans_null_count, \\\n",
    "sum(case when foreign_born is null then 1 else 0 end) as foreign_born_null_count, \\\n",
    "sum(case when average_household_size is null then 1 else 0 end) as average_household_size_null_count, \\\n",
    "sum(case when AmericanIndian_and_AlaskaNative_population is null then 1 else 0 end) as AmericanIndian_and_AlaskaNative_population_null_count, \\\n",
    "sum(case when Asian_population is null then 1 else 0 end) as Asian_population_null_count, \\\n",
    "sum(case when Black_or_AfricanAmerican_population is null then 1 else 0 end) as Black_or_AfricanAmerican_population_null_count, \\\n",
    "sum(case when Hispanic_or_Latino_population is null then 1 else 0 end) as Hispanic_or_Latino_population_null_count, \\\n",
    "sum(case when White_population is null then 1 else 0 end) as White_population_null_count \\\n",
    "from demographic;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * postgresql://student:***@127.0.0.1/immigrationdb\n",
      "5 rows affected.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr>\n",
       "        <th>state</th>\n",
       "        <th>state_code</th>\n",
       "        <th>population</th>\n",
       "        <th>median_age</th>\n",
       "        <th>male_population</th>\n",
       "        <th>female_population</th>\n",
       "        <th>number_of_veterans</th>\n",
       "        <th>foreign_born</th>\n",
       "        <th>average_household_size</th>\n",
       "        <th>americanindian_and_alaskanative_population</th>\n",
       "        <th>asian_population</th>\n",
       "        <th>black_or_africanamerican_population</th>\n",
       "        <th>hispanic_or_latino_population</th>\n",
       "        <th>white_population</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>ALABAMA</td>\n",
       "        <td>AL</td>\n",
       "        <td>1096154</td>\n",
       "        <td>38.0</td>\n",
       "        <td>2448200</td>\n",
       "        <td>2715106</td>\n",
       "        <td>352896</td>\n",
       "        <td>252541</td>\n",
       "        <td>2.0</td>\n",
       "        <td>8084</td>\n",
       "        <td>28769</td>\n",
       "        <td>521068</td>\n",
       "        <td>39313</td>\n",
       "        <td>498920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>ALASKA</td>\n",
       "        <td>AK</td>\n",
       "        <td>336228</td>\n",
       "        <td>32.2</td>\n",
       "        <td>764725</td>\n",
       "        <td>728750</td>\n",
       "        <td>137460</td>\n",
       "        <td>166290</td>\n",
       "        <td>2.0</td>\n",
       "        <td>36339</td>\n",
       "        <td>36825</td>\n",
       "        <td>23107</td>\n",
       "        <td>27261</td>\n",
       "        <td>212696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>ARIZONA</td>\n",
       "        <td>AZ</td>\n",
       "        <td>5754881</td>\n",
       "        <td>34.1</td>\n",
       "        <td>11137275</td>\n",
       "        <td>11360435</td>\n",
       "        <td>1322525</td>\n",
       "        <td>3411565</td>\n",
       "        <td>2.19</td>\n",
       "        <td>129708</td>\n",
       "        <td>229183</td>\n",
       "        <td>296222</td>\n",
       "        <td>1508157</td>\n",
       "        <td>3591611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>ARKANSAS</td>\n",
       "        <td>AR</td>\n",
       "        <td>643597</td>\n",
       "        <td>32.6</td>\n",
       "        <td>1400724</td>\n",
       "        <td>1482165</td>\n",
       "        <td>154390</td>\n",
       "        <td>307753</td>\n",
       "        <td>2.17</td>\n",
       "        <td>9381</td>\n",
       "        <td>22062</td>\n",
       "        <td>149608</td>\n",
       "        <td>77813</td>\n",
       "        <td>384733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>CALIFORNIA</td>\n",
       "        <td>CA</td>\n",
       "        <td>31753718</td>\n",
       "        <td>35.8</td>\n",
       "        <td>61055672</td>\n",
       "        <td>62388681</td>\n",
       "        <td>4617022</td>\n",
       "        <td>37059662</td>\n",
       "        <td>2.59</td>\n",
       "        <td>401386</td>\n",
       "        <td>4543730</td>\n",
       "        <td>2047009</td>\n",
       "        <td>9856464</td>\n",
       "        <td>14905129</td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "[('ALABAMA', 'AL', 1096154, 38.0, 2448200, 2715106, 352896, 252541, 2.0, 8084, 28769, 521068, 39313, 498920),\n",
       " ('ALASKA', 'AK', 336228, 32.2, 764725, 728750, 137460, 166290, 2.0, 36339, 36825, 23107, 27261, 212696),\n",
       " ('ARIZONA', 'AZ', 5754881, 34.1, 11137275, 11360435, 1322525, 3411565, 2.19, 129708, 229183, 296222, 1508157, 3591611),\n",
       " ('ARKANSAS', 'AR', 643597, 32.6, 1400724, 1482165, 154390, 307753, 2.17, 9381, 22062, 149608, 77813, 384733),\n",
       " ('CALIFORNIA', 'CA', 31753718, 35.8, 61055672, 62388681, 4617022, 37059662, 2.59, 401386, 4543730, 2047009, 9856464, 14905129)]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%sql SELECT * FROM demographic LIMIT 5;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23607, 22)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "immigration.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                           0\n",
       "created_date                 0\n",
       "admission_no                 0\n",
       "admitted_date                0\n",
       "departure_date               0\n",
       "arrival_date                 0\n",
       "port_name                    0\n",
       "airport_name             12370\n",
       "entry_state_id           12370\n",
       "entry_state_name         12370\n",
       "entry_county             12370\n",
       "airline                      0\n",
       "flight_no                    0\n",
       "gender                       0\n",
       "birth_year                   0\n",
       "age                          0\n",
       "origin_country_name       4340\n",
       "resident_country_name     1552\n",
       "visa_type                    0\n",
       "visa_type_name               0\n",
       "state_code                   0\n",
       "current_state_name         990\n",
       "dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "immigration.isnull().sum(axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * postgresql://student:***@127.0.0.1/immigrationdb\n",
      "1 rows affected.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr>\n",
       "        <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>23607</td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "[(23607,)]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%sql SELECT count(*) FROM immigration;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * postgresql://student:***@127.0.0.1/immigrationdb\n",
      "1 rows affected.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr>\n",
       "        <th>id</th>\n",
       "        <th>created_date</th>\n",
       "        <th>admission_no</th>\n",
       "        <th>admitted_date</th>\n",
       "        <th>departure_date</th>\n",
       "        <th>arrival_date</th>\n",
       "        <th>port_name</th>\n",
       "        <th>airport_name</th>\n",
       "        <th>entry_state_id</th>\n",
       "        <th>entry_state_name</th>\n",
       "        <th>entry_county</th>\n",
       "        <th>airline</th>\n",
       "        <th>flight_no</th>\n",
       "        <th>birth_year</th>\n",
       "        <th>age</th>\n",
       "        <th>origin_country_name</th>\n",
       "        <th>resident_country_name</th>\n",
       "        <th>visa_type</th>\n",
       "        <th>visa_type_name</th>\n",
       "        <th>state_code</th>\n",
       "        <th>current_state_name</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>0</td>\n",
       "        <td>0</td>\n",
       "        <td>0</td>\n",
       "        <td>0</td>\n",
       "        <td>0</td>\n",
       "        <td>0</td>\n",
       "        <td>0</td>\n",
       "        <td>12370</td>\n",
       "        <td>12370</td>\n",
       "        <td>12370</td>\n",
       "        <td>12370</td>\n",
       "        <td>0</td>\n",
       "        <td>0</td>\n",
       "        <td>0</td>\n",
       "        <td>0</td>\n",
       "        <td>4340</td>\n",
       "        <td>1552</td>\n",
       "        <td>0</td>\n",
       "        <td>0</td>\n",
       "        <td>0</td>\n",
       "        <td>990</td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "[(0, 0, 0, 0, 0, 0, 0, 12370, 12370, 12370, 12370, 0, 0, 0, 0, 4340, 1552, 0, 0, 0, 990)]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%sql SELECT \\\n",
    "sum(case when id is null then 1 else 0 end) as id, \\\n",
    "sum(case when created_date is null then 1 else 0 end) as created_date,\\\n",
    "sum(case when admission_no is null then 1 else 0 end) as admission_no, \\\n",
    "sum(case when admitted_date is null then 1 else 0 end) as admitted_date, \\\n",
    "sum(case when departure_date is null then 1 else 0 end) as departure_date, \\\n",
    "sum(case when arrival_date is null then 1 else 0 end) as arrival_date, \\\n",
    "sum(case when port_name is null then 1 else 0 end) as port_name, \\\n",
    "sum(case when airport_name is null then 1 else 0 end) as airport_name, \\\n",
    "sum(case when entry_state_id is null then 1 else 0 end) as entry_state_id, \\\n",
    "sum(case when entry_state_name is null then 1 else 0 end) as entry_state_name, \\\n",
    "sum(case when entry_county is null then 1 else 0 end) as entry_county, \\\n",
    "sum(case when airline is null then 1 else 0 end) as airline, \\\n",
    "sum(case when flight_no is null then 1 else 0 end) as flight_no, \\\n",
    "sum(case when birth_year is null then 1 else 0 end) as birth_year, \\\n",
    "sum(case when age is null then 1 else 0 end) as age, \\\n",
    "sum(case when origin_country_name is null then 1 else 0 end) as origin_country_name, \\\n",
    "sum(case when resident_country_name is null then 1 else 0 end) as resident_country_name, \\\n",
    "sum(case when visa_type is null then 1 else 0 end) as visa_type, \\\n",
    "sum(case when visa_type_name is null then 1 else 0 end) as visa_type_name, \\\n",
    "sum(case when state_code is null then 1 else 0 end) as state_code, \\\n",
    "sum(case when current_state_name is null then 1 else 0 end) as current_state_name \\\n",
    "from immigration;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * postgresql://student:***@127.0.0.1/immigrationdb\n",
      "5 rows affected.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr>\n",
       "        <th>id</th>\n",
       "        <th>created_date</th>\n",
       "        <th>admission_no</th>\n",
       "        <th>admitted_date</th>\n",
       "        <th>departure_date</th>\n",
       "        <th>arrival_date</th>\n",
       "        <th>port_name</th>\n",
       "        <th>airport_name</th>\n",
       "        <th>entry_state_id</th>\n",
       "        <th>entry_state_name</th>\n",
       "        <th>entry_county</th>\n",
       "        <th>airline</th>\n",
       "        <th>flight_no</th>\n",
       "        <th>gender</th>\n",
       "        <th>birth_year</th>\n",
       "        <th>age</th>\n",
       "        <th>origin_country_name</th>\n",
       "        <th>resident_country_name</th>\n",
       "        <th>visa_type</th>\n",
       "        <th>visa_type_name</th>\n",
       "        <th>state_code</th>\n",
       "        <th>current_state_name</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>1973857</td>\n",
       "        <td>2016-04-11</td>\n",
       "        <td>2147483647</td>\n",
       "        <td>2016-07-09</td>\n",
       "        <td>2016-04-25</td>\n",
       "        <td>2016-04-11</td>\n",
       "        <td>NEWARK/TETERBORO</td>\n",
       "        <td>Lakefront Airport</td>\n",
       "        <td>LA</td>\n",
       "        <td>LOUISIANA</td>\n",
       "        <td>New Orleans</td>\n",
       "        <td>UA</td>\n",
       "        <td>00998</td>\n",
       "        <td>F</td>\n",
       "        <td>1990</td>\n",
       "        <td>26</td>\n",
       "        <td>BELGIUM</td>\n",
       "        <td>BELGIUM</td>\n",
       "        <td>2</td>\n",
       "        <td>Pleasure</td>\n",
       "        <td>AZ</td>\n",
       "        <td>ARIZONA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>3700217</td>\n",
       "        <td>2016-04-20</td>\n",
       "        <td>2147483647</td>\n",
       "        <td>2016-10-19</td>\n",
       "        <td>2016-05-22</td>\n",
       "        <td>2016-04-20</td>\n",
       "        <td>NEWARK/TETERBORO</td>\n",
       "        <td>Lakefront Airport</td>\n",
       "        <td>LA</td>\n",
       "        <td>LOUISIANA</td>\n",
       "        <td>New Orleans</td>\n",
       "        <td>UA</td>\n",
       "        <td>00961</td>\n",
       "        <td>M</td>\n",
       "        <td>1981</td>\n",
       "        <td>35</td>\n",
       "        <td>INDIA</td>\n",
       "        <td>INDIA</td>\n",
       "        <td>1</td>\n",
       "        <td>Business</td>\n",
       "        <td>SC</td>\n",
       "        <td>SOUTH CAROLINA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>641170</td>\n",
       "        <td>2016-04-04</td>\n",
       "        <td>2147483647</td>\n",
       "        <td>2016-07-02</td>\n",
       "        <td>2016-04-07</td>\n",
       "        <td>2016-04-04</td>\n",
       "        <td>NEWARK/TETERBORO</td>\n",
       "        <td>Lakefront Airport</td>\n",
       "        <td>LA</td>\n",
       "        <td>LOUISIANA</td>\n",
       "        <td>New Orleans</td>\n",
       "        <td>LH</td>\n",
       "        <td>00402</td>\n",
       "        <td>M</td>\n",
       "        <td>1966</td>\n",
       "        <td>50</td>\n",
       "        <td>ITALY</td>\n",
       "        <td>ITALY</td>\n",
       "        <td>1</td>\n",
       "        <td>Business</td>\n",
       "        <td>SC</td>\n",
       "        <td>SOUTH CAROLINA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>4280680</td>\n",
       "        <td>2016-04-23</td>\n",
       "        <td>2147483647</td>\n",
       "        <td>2016-07-21</td>\n",
       "        <td>2016-04-30</td>\n",
       "        <td>2016-04-23</td>\n",
       "        <td>NEWARK/TETERBORO</td>\n",
       "        <td>Lakefront Airport</td>\n",
       "        <td>LA</td>\n",
       "        <td>LOUISIANA</td>\n",
       "        <td>New Orleans</td>\n",
       "        <td>BA</td>\n",
       "        <td>00185</td>\n",
       "        <td>M</td>\n",
       "        <td>1958</td>\n",
       "        <td>58</td>\n",
       "        <td>SWITZERLAND</td>\n",
       "        <td>SWITZERLAND</td>\n",
       "        <td>2</td>\n",
       "        <td>Pleasure</td>\n",
       "        <td>SC</td>\n",
       "        <td>SOUTH CAROLINA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>3892965</td>\n",
       "        <td>2016-04-21</td>\n",
       "        <td>2147483647</td>\n",
       "        <td>2016-10-20</td>\n",
       "        <td>2016-09-10</td>\n",
       "        <td>2016-04-21</td>\n",
       "        <td>NEWARK/TETERBORO</td>\n",
       "        <td>Lakefront Airport</td>\n",
       "        <td>LA</td>\n",
       "        <td>LOUISIANA</td>\n",
       "        <td>New Orleans</td>\n",
       "        <td>UA</td>\n",
       "        <td>00180</td>\n",
       "        <td>F</td>\n",
       "        <td>1960</td>\n",
       "        <td>56</td>\n",
       "        <td>CHINA</td>\n",
       "        <td>CHINA</td>\n",
       "        <td>2</td>\n",
       "        <td>Pleasure</td>\n",
       "        <td>SC</td>\n",
       "        <td>SOUTH CAROLINA</td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "[(1973857, datetime.date(2016, 4, 11), 2147483647, datetime.date(2016, 7, 9), datetime.date(2016, 4, 25), datetime.date(2016, 4, 11), 'NEWARK/TETERBORO', 'Lakefront Airport', 'LA', 'LOUISIANA', 'New Orleans', 'UA', '00998', 'F', 1990, 26, 'BELGIUM', 'BELGIUM', 2, 'Pleasure', 'AZ', 'ARIZONA'),\n",
       " (3700217, datetime.date(2016, 4, 20), 2147483647, datetime.date(2016, 10, 19), datetime.date(2016, 5, 22), datetime.date(2016, 4, 20), 'NEWARK/TETERBORO', 'Lakefront Airport', 'LA', 'LOUISIANA', 'New Orleans', 'UA', '00961', 'M', 1981, 35, 'INDIA', 'INDIA', 1, 'Business', 'SC', 'SOUTH CAROLINA'),\n",
       " (641170, datetime.date(2016, 4, 4), 2147483647, datetime.date(2016, 7, 2), datetime.date(2016, 4, 7), datetime.date(2016, 4, 4), 'NEWARK/TETERBORO', 'Lakefront Airport', 'LA', 'LOUISIANA', 'New Orleans', 'LH', '00402', 'M', 1966, 50, 'ITALY', 'ITALY', 1, 'Business', 'SC', 'SOUTH CAROLINA'),\n",
       " (4280680, datetime.date(2016, 4, 23), 2147483647, datetime.date(2016, 7, 21), datetime.date(2016, 4, 30), datetime.date(2016, 4, 23), 'NEWARK/TETERBORO', 'Lakefront Airport', 'LA', 'LOUISIANA', 'New Orleans', 'BA', '00185', 'M', 1958, 58, 'SWITZERLAND', 'SWITZERLAND', 2, 'Pleasure', 'SC', 'SOUTH CAROLINA'),\n",
       " (3892965, datetime.date(2016, 4, 21), 2147483647, datetime.date(2016, 10, 20), datetime.date(2016, 9, 10), datetime.date(2016, 4, 21), 'NEWARK/TETERBORO', 'Lakefront Airport', 'LA', 'LOUISIANA', 'New Orleans', 'UA', '00180', 'F', 1960, 56, 'CHINA', 'CHINA', 2, 'Pleasure', 'SC', 'SOUTH CAROLINA')]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%sql SELECT * FROM immigration LIMIT 5;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2577, 17)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crime.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "county                                  0\n",
       "state                                   0\n",
       "category                                0\n",
       "total_crime                             0\n",
       "violent_crime                           0\n",
       "murder_and_nonnegligent_manslaughter    0\n",
       "robbery                                 0\n",
       "aggravated_assault                      0\n",
       "property_crime                          0\n",
       "burglary                                0\n",
       "larceny-theft                           0\n",
       "motor_vehicle_theft                     0\n",
       "arson3                                  0\n",
       "rape                                    0\n",
       "crime_rate                              0\n",
       "violent_crime_rate                      0\n",
       "property_crime_rate                     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crime.isnull().sum(axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * postgresql://student:***@127.0.0.1/immigrationdb\n",
      "1 rows affected.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr>\n",
       "        <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>2555</td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "[(2555,)]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%sql SELECT count(*) FROM crime;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * postgresql://student:***@127.0.0.1/immigrationdb\n",
      "1 rows affected.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr>\n",
       "        <th>county</th>\n",
       "        <th>state</th>\n",
       "        <th>category</th>\n",
       "        <th>total_crime</th>\n",
       "        <th>violent_crime</th>\n",
       "        <th>murder_and_nonnegligent_manslaughter</th>\n",
       "        <th>robbery</th>\n",
       "        <th>aggravated_assault</th>\n",
       "        <th>property_crime</th>\n",
       "        <th>burglary</th>\n",
       "        <th>larceny_theft</th>\n",
       "        <th>motor_vehicle_theft</th>\n",
       "        <th>arson3</th>\n",
       "        <th>rape</th>\n",
       "        <th>crime_rate</th>\n",
       "        <th>violent_crime_rate</th>\n",
       "        <th>property_crime_rate</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>0</td>\n",
       "        <td>0</td>\n",
       "        <td>0</td>\n",
       "        <td>0</td>\n",
       "        <td>0</td>\n",
       "        <td>0</td>\n",
       "        <td>0</td>\n",
       "        <td>0</td>\n",
       "        <td>0</td>\n",
       "        <td>0</td>\n",
       "        <td>0</td>\n",
       "        <td>0</td>\n",
       "        <td>0</td>\n",
       "        <td>0</td>\n",
       "        <td>0</td>\n",
       "        <td>0</td>\n",
       "        <td>0</td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "[(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0)]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%sql SELECT \\\n",
    "sum(case when county is null then 1 else 0 end) as county, \\\n",
    "sum(case when state is null then 1 else 0 end) as state,\\\n",
    "sum(case when category is null then 1 else 0 end) as category,\\\n",
    "sum(case when total_crime is null then 1 else 0 end) as total_crime, \\\n",
    "sum(case when violent_crime is null then 1 else 0 end) as violent_crime, \\\n",
    "sum(case when murder_and_nonnegligent_manslaughter is null then 1 else 0 end) as murder_and_nonnegligent_manslaughter, \\\n",
    "sum(case when robbery is null then 1 else 0 end) as robbery, \\\n",
    "sum(case when aggravated_assault is null then 1 else 0 end) as aggravated_assault, \\\n",
    "sum(case when property_crime is null then 1 else 0 end) as property_crime, \\\n",
    "sum(case when burglary is null then 1 else 0 end) as burglary, \\\n",
    "sum(case when larceny_theft is null then 1 else 0 end) as larceny_theft, \\\n",
    "sum(case when motor_vehicle_theft is null then 1 else 0 end) as motor_vehicle_theft, \\\n",
    "sum(case when arson3 is null then 1 else 0 end) as arson3, \\\n",
    "sum(case when rape is null then 1 else 0 end) as rape, \\\n",
    "sum(case when crime_rate is null then 1 else 0 end) as crime_rate, \\\n",
    "sum(case when violent_crime_rate is null then 1 else 0 end) as violent_crime_rate, \\\n",
    "sum(case when property_crime_rate is null then 1 else 0 end) as property_crime_rate \\\n",
    "from crime;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * postgresql://student:***@127.0.0.1/immigrationdb\n",
      "5 rows affected.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr>\n",
       "        <th>county</th>\n",
       "        <th>state</th>\n",
       "        <th>category</th>\n",
       "        <th>total_crime</th>\n",
       "        <th>violent_crime</th>\n",
       "        <th>murder_and_nonnegligent_manslaughter</th>\n",
       "        <th>robbery</th>\n",
       "        <th>aggravated_assault</th>\n",
       "        <th>property_crime</th>\n",
       "        <th>burglary</th>\n",
       "        <th>larceny_theft</th>\n",
       "        <th>motor_vehicle_theft</th>\n",
       "        <th>arson3</th>\n",
       "        <th>rape</th>\n",
       "        <th>crime_rate</th>\n",
       "        <th>violent_crime_rate</th>\n",
       "        <th>property_crime_rate</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>Autauga</td>\n",
       "        <td>ALABAMA</td>\n",
       "        <td> Metropolitan Counties</td>\n",
       "        <td>419</td>\n",
       "        <td>69</td>\n",
       "        <td>0</td>\n",
       "        <td>6</td>\n",
       "        <td>50</td>\n",
       "        <td>344</td>\n",
       "        <td>111</td>\n",
       "        <td>187</td>\n",
       "        <td>46</td>\n",
       "        <td>0</td>\n",
       "        <td>13</td>\n",
       "        <td>972.5</td>\n",
       "        <td>160.1</td>\n",
       "        <td>798.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>Baldwin</td>\n",
       "        <td>ALABAMA</td>\n",
       "        <td> Metropolitan Counties</td>\n",
       "        <td>796</td>\n",
       "        <td>115</td>\n",
       "        <td>0</td>\n",
       "        <td>33</td>\n",
       "        <td>73</td>\n",
       "        <td>648</td>\n",
       "        <td>225</td>\n",
       "        <td>390</td>\n",
       "        <td>33</td>\n",
       "        <td>0</td>\n",
       "        <td>9</td>\n",
       "        <td>406.1</td>\n",
       "        <td>58.7</td>\n",
       "        <td>330.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>Bibb</td>\n",
       "        <td>ALABAMA</td>\n",
       "        <td> Metropolitan Counties</td>\n",
       "        <td>49</td>\n",
       "        <td>7</td>\n",
       "        <td>0</td>\n",
       "        <td>1</td>\n",
       "        <td>4</td>\n",
       "        <td>41</td>\n",
       "        <td>20</td>\n",
       "        <td>18</td>\n",
       "        <td>3</td>\n",
       "        <td>0</td>\n",
       "        <td>2</td>\n",
       "        <td>366.6</td>\n",
       "        <td>52.4</td>\n",
       "        <td>306.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>Blount</td>\n",
       "        <td>ALABAMA</td>\n",
       "        <td> Metropolitan Counties</td>\n",
       "        <td>1046</td>\n",
       "        <td>204</td>\n",
       "        <td>5</td>\n",
       "        <td>5</td>\n",
       "        <td>178</td>\n",
       "        <td>832</td>\n",
       "        <td>247</td>\n",
       "        <td>503</td>\n",
       "        <td>82</td>\n",
       "        <td>0</td>\n",
       "        <td>16</td>\n",
       "        <td>5878.7</td>\n",
       "        <td>1146.5</td>\n",
       "        <td>4676.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>Calhoun</td>\n",
       "        <td>ALABAMA</td>\n",
       "        <td> Metropolitan Counties</td>\n",
       "        <td>430</td>\n",
       "        <td>16</td>\n",
       "        <td>0</td>\n",
       "        <td>1</td>\n",
       "        <td>11</td>\n",
       "        <td>413</td>\n",
       "        <td>181</td>\n",
       "        <td>225</td>\n",
       "        <td>7</td>\n",
       "        <td>0</td>\n",
       "        <td>4</td>\n",
       "        <td>309.1</td>\n",
       "        <td>11.5</td>\n",
       "        <td>296.9</td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "[('Autauga', 'ALABAMA', ' Metropolitan Counties', 419, 69, 0, 6, 50, 344, 111, 187, 46, 0, 13, 972.5, 160.1, 798.4),\n",
       " ('Baldwin', 'ALABAMA', ' Metropolitan Counties', 796, 115, 0, 33, 73, 648, 225, 390, 33, 0, 9, 406.1, 58.7, 330.6),\n",
       " ('Bibb', 'ALABAMA', ' Metropolitan Counties', 49, 7, 0, 1, 4, 41, 20, 18, 3, 0, 2, 366.6, 52.4, 306.8),\n",
       " ('Blount', 'ALABAMA', ' Metropolitan Counties', 1046, 204, 5, 5, 178, 832, 247, 503, 82, 0, 16, 5878.7, 1146.5, 4676.0),\n",
       " ('Calhoun', 'ALABAMA', ' Metropolitan Counties', 430, 16, 0, 1, 11, 413, 181, 225, 7, 0, 4, 309.1, 11.5, 296.9)]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%sql SELECT * FROM crime LIMIT 5;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(208, 5)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temperature.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "county                            0\n",
       "state                             0\n",
       "avg_temperature                   0\n",
       "max_of_monthly_avg_temperature    0\n",
       "min_of_monthly_avg_temperature    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temperature.isnull().sum(axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * postgresql://student:***@127.0.0.1/immigrationdb\n",
      "1 rows affected.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr>\n",
       "        <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>208</td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "[(208,)]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%sql SELECT count(*) FROM temperature;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * postgresql://student:***@127.0.0.1/immigrationdb\n",
      "1 rows affected.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr>\n",
       "        <th>county</th>\n",
       "        <th>state</th>\n",
       "        <th>avg_temperature</th>\n",
       "        <th>max_of_monthly_avg_temperature</th>\n",
       "        <th>min_of_monthly_avg_temperature</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>0</td>\n",
       "        <td>0</td>\n",
       "        <td>0</td>\n",
       "        <td>0</td>\n",
       "        <td>0</td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "[(0, 0, 0, 0, 0)]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%sql SELECT \\\n",
    "sum(case when county is null then 1 else 0 end) as county, \\\n",
    "sum(case when state is null then 1 else 0 end) as state,\\\n",
    "sum(case when avg_temperature is null then 1 else 0 end) as avg_temperature, \\\n",
    "sum(case when max_of_monthly_avg_temperature is null then 1 else 0 end) as max_of_monthly_avg_temperature, \\\n",
    "sum(case when min_of_monthly_avg_temperature is null then 1 else 0 end) as min_of_monthly_avg_temperature \\\n",
    "from temperature;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * postgresql://student:***@127.0.0.1/immigrationdb\n",
      "5 rows affected.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr>\n",
       "        <th>county</th>\n",
       "        <th>state</th>\n",
       "        <th>avg_temperature</th>\n",
       "        <th>max_of_monthly_avg_temperature</th>\n",
       "        <th>min_of_monthly_avg_temperature</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>Allegheny</td>\n",
       "        <td>PENNSYLVANIA</td>\n",
       "        <td>9.61</td>\n",
       "        <td>28.6</td>\n",
       "        <td>-11.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>Allen</td>\n",
       "        <td>INDIANA</td>\n",
       "        <td>9.7</td>\n",
       "        <td>29.04</td>\n",
       "        <td>-12.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>Bell</td>\n",
       "        <td>TEXAS</td>\n",
       "        <td>18.54</td>\n",
       "        <td>32.66</td>\n",
       "        <td>1.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>Bernalillo</td>\n",
       "        <td>NEW MEXICO</td>\n",
       "        <td>11.14</td>\n",
       "        <td>25.69</td>\n",
       "        <td>-5.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>Broward</td>\n",
       "        <td>FLORIDA</td>\n",
       "        <td>23.07</td>\n",
       "        <td>30.13</td>\n",
       "        <td>12.96</td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "[('Allegheny', 'PENNSYLVANIA', 9.61, 28.6, -11.42),\n",
       " ('Allen', 'INDIANA', 9.7, 29.04, -12.44),\n",
       " ('Bell', 'TEXAS', 18.54, 32.66, 1.67),\n",
       " ('Bernalillo', 'NEW MEXICO', 11.14, 25.69, -5.07),\n",
       " ('Broward', 'FLORIDA', 23.07, 30.13, 12.96)]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%sql SELECT * FROM temperature LIMIT 5;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(71, 6)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "created_date    0\n",
       "day             0\n",
       "week            0\n",
       "month           0\n",
       "year            0\n",
       "weekday         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date.isnull().sum(axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * postgresql://student:***@127.0.0.1/immigrationdb\n",
      "1 rows affected.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr>\n",
       "        <th>created_date</th>\n",
       "        <th>day</th>\n",
       "        <th>week</th>\n",
       "        <th>month</th>\n",
       "        <th>year</th>\n",
       "        <th>weekday</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>0</td>\n",
       "        <td>0</td>\n",
       "        <td>0</td>\n",
       "        <td>0</td>\n",
       "        <td>0</td>\n",
       "        <td>0</td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "[(0, 0, 0, 0, 0, 0)]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%sql SELECT \\\n",
    "sum(case when created_date is null then 1 else 0 end) as created_date, \\\n",
    "sum(case when day is null then 1 else 0 end) as day,\\\n",
    "sum(case when week is null then 1 else 0 end) as week, \\\n",
    "sum(case when month is null then 1 else 0 end) as month, \\\n",
    "sum(case when year is null then 1 else 0 end) as year, \\\n",
    "sum(case when weekday is null then 1 else 0 end) as weekday \\\n",
    "from date;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * postgresql://student:***@127.0.0.1/immigrationdb\n",
      "1 rows affected.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr>\n",
       "        <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>71</td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "[(71,)]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%sql SELECT count(*) FROM date;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * postgresql://student:***@127.0.0.1/immigrationdb\n",
      "5 rows affected.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr>\n",
       "        <th>created_date</th>\n",
       "        <th>day</th>\n",
       "        <th>week</th>\n",
       "        <th>month</th>\n",
       "        <th>year</th>\n",
       "        <th>weekday</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>2016-06-23</td>\n",
       "        <td>23</td>\n",
       "        <td>25</td>\n",
       "        <td>6</td>\n",
       "        <td>2016</td>\n",
       "        <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>2016-04-14</td>\n",
       "        <td>14</td>\n",
       "        <td>15</td>\n",
       "        <td>4</td>\n",
       "        <td>2016</td>\n",
       "        <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>2016-05-24</td>\n",
       "        <td>24</td>\n",
       "        <td>21</td>\n",
       "        <td>5</td>\n",
       "        <td>2016</td>\n",
       "        <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>2016-05-26</td>\n",
       "        <td>26</td>\n",
       "        <td>21</td>\n",
       "        <td>5</td>\n",
       "        <td>2016</td>\n",
       "        <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>2016-05-03</td>\n",
       "        <td>3</td>\n",
       "        <td>18</td>\n",
       "        <td>5</td>\n",
       "        <td>2016</td>\n",
       "        <td>3</td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "[(datetime.date(2016, 6, 23), 23, 25, 6, 2016, 5),\n",
       " (datetime.date(2016, 4, 14), 14, 15, 4, 2016, 5),\n",
       " (datetime.date(2016, 5, 24), 24, 21, 5, 2016, 3),\n",
       " (datetime.date(2016, 5, 26), 26, 21, 5, 2016, 5),\n",
       " (datetime.date(2016, 5, 3), 3, 18, 5, 2016, 3)]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%sql SELECT * FROM date LIMIT 5;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3 Data dictionary \n",
    "\n",
    "###### 1. immigration\n",
    "- This table contains i94 immigrations data.\n",
    "- It comes from \"US National Tourism and Trade Office\".\n",
    "- It shows you information about each immigrant id whose resident country was Japan, and who was registered in i94 system during 2016.\n",
    "\n",
    "| Field Name | Data Type | Description | Example |\n",
    "| --- | --- | --- | --- |\n",
    "| **id** *Primary key* | int | unique id of I94 immigration record | 4526055 |\n",
    "| created_date *Foreign key* | date | date the data was created | 4/24/2016 |\n",
    "| admission_no | int | admission no. of immigrants | 2147483647 |\n",
    "| admitted_date | date | date the immigrants were admitted for the entry | 7/22/2016 |\n",
    "| departure_date | date | date the immigrants departed the US | 4/28/2016 |\n",
    "| arrival_date | date | date the immigrants arrived to the US | 4/24/2016 |\n",
    "| port_name | varchar | airport code of immigrants's entry | NEWARK/TETERBORO |\n",
    "| airport_name | varchar | airport name of immigrants's entry | Lakefront Airport |\n",
    "| entry_state_id | varchar | state code of immigrants' entry | LA |\n",
    "| **entry_state_name**　*Foreign key* | varchar | state name of immigrants' entry | LOUISIANA |\n",
    "| **entry_county**　*Foreign key* | varchar | county name of immigrants' entry | New Orleans |\n",
    "| airline | varchar | airline used by immigrants for entry | JL |\n",
    "| flight_no | varchar | flight no. used by immigrants for entry | 60 |\n",
    "| gender | varchar | gender of immigrants | M |\n",
    "| birth_year | int | birth year of immigrants | 1971 |\n",
    "| age | int | age of immigrants | 45 |\n",
    "| origin_country_name | varchar | original country of immigrants | JAPAN |\n",
    "| resident_country_name | varchar | resident country of immigrants | JAPAN |\n",
    "| visa_type | bigint | immigrants' visa type code | 1 |\n",
    "| visa_type_name | varchar | immigrants' visa type name | Business |\n",
    "| state_code | varchar | state code of immigrants's final destination | AZ |\n",
    "| **current_state_name**　*Foreign key* | varchar | state name of immigrants' final destination | ARIZONA |\n",
    "\n",
    "###### 2. demographic\n",
    "- This table contains basic demographic information of the US of 2015.\n",
    "- It comes from \"OpenSoft\".\n",
    "- It allows you to join by Primary key 'state' with the fact table to dig in more deeply about the satistics of the places immigrants chose to enter or end up staying in the end.\n",
    "\n",
    "| Field Name | Data Type | Description | Example |\n",
    "| --- | --- | --- | --- |\n",
    "| **state** *Primary key* | varchar | state name | ALABAMA |\n",
    "| state_code | varchar | state code | AL |\n",
    "| population | int | population | 1096154 |\n",
    "| median_age | float | median age | 38 |\n",
    "| male_population | int | male population | 2448200 |\n",
    "| female_population | int | female population | 2715106 |\n",
    "| number_of_veterans | int | number of veterans | 352896 |\n",
    "| foreign_born | int | number of foreign-born | 252541 |\n",
    "| average_household_size | float | avg of household size | 2 |\n",
    "| AmericanIndian_and_AlaskaNative_population | int | Native American and Alaskan Native population | 8084 |\n",
    "| Asian_population | int | Asian population | 28769 |\n",
    "| Black_or_AfricanAmerican_population | int | Black of African Americn population | 521068 | \n",
    "| Hispanic_or_Latino_population | int | Hispanic or Latino population | 39313 |\n",
    "| White_population | int | White population| 498920 |\n",
    "\n",
    "###### 3. crime\n",
    "- This table contains number of crimes by US state and county of 2015.\n",
    "- It comes from \"data.world\".\n",
    "- It allows you to join by Composite key 'state' and 'county' with the fact table to understand crime situations including crime rate of the places immigrants chose to enter or end up staying in the end.\n",
    "\n",
    "| Field Name | Data Type | Description | Example |\n",
    "| --- | --- | --- | --- |\n",
    "| **county** *Composite key* | varchar | county name | Autauga |\n",
    "| **state** *Composite key* | varchar | state name | ALABAMA |\n",
    "| category | varchar | category of county | Metropolitan Counties |\n",
    "| total_crime | int | total number of crimes | 2/22/1901 |\n",
    "| violent_crime | int | number of violent crimes | 3/9/1900 |\n",
    "| murder_and_nonnegligent_manslaughter | int | number of murders and nonnegligent manslaughters | 1/0/1900 |\n",
    "| robbery | int | number of robberies | 6 |\n",
    "| aggravated_assault | int | number of aggravated assaults | 50 |\n",
    "| burglary | int | number of burglaries | 344 |\n",
    "| property_crime | int | number of property crimes | 111 |\n",
    "| larceny_theft | int | number of larceny thefts | 187 |\n",
    "| motor_vehicle_theft | int | number of motor vehicle thefts | 46 |\n",
    "| arson3 | int | number of arsons | 0 |\n",
    "| rape | int | number of rapes | 13 |\n",
    "| crime_rate | float | crime rate(per 100,000 people) | 972.5 |\n",
    "| violent_crime_rate | float | crime rate of violent crimes(per 100,000 people) | 160.1 |\n",
    "| property_crime_rate | float | crime rate of property crimes(per 100,000 people) | 798.4 |\n",
    "\n",
    "###### 4. temperature\n",
    "- This table contains global temperature information since 1970s by US state and county.\n",
    "- It comes from \"Kaggle\".\n",
    "- It allows you to join by Composite key 'state' and 'county' with the fact table to understand the statistics of temperature of the places immigrants chose to enter or end up staying in the end.\n",
    "\n",
    "| Field Name | Data Type | Description | Example |\n",
    "| --- | --- | --- | --- |\n",
    "| **county** *Composite key* | varchar | county name | Allegheny |\n",
    "| **state** *Composite key* | varchar | state name | PENNSYLVANIA |\n",
    "| avg_temperature | float | average of monthly average temperature in 1970-2016  | 9.61 |\n",
    "| max_of_monthly_avg_temperature | float | max value of of monthly average temperature in 1970-2016 | 28.6 |\n",
    "| min_of_monthly_avg_temperature | float | minimum value of of monthly average temperature in 1970-2016 | -11.42 |\n",
    "\n",
    "###### 5. date\n",
    "- This table is the breakdown of immigration table's 'created date' column.\n",
    "- It allows you to join by Primary key 'created_date' with the fact table to analyze from date perspective.\n",
    "\n",
    "| Field Name | Data Type | Description | Example |\n",
    "| --- | --- | --- | --- |\n",
    "| **created_date** *Primary key* | date | date the immigration record was created | 6/23/2016 |\n",
    "| day | int | date of created_date | 23 |\n",
    "| week | int | week of created_date | 25 |\n",
    "| month | int | month of created_date | 6 |\n",
    "| year | int | year of created_date | 2016 |\n",
    "| weekday | int | weekday of created_date | 5 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 5: Complete Project Write Up\n",
    "###### 1. Why I chose the technologies I used for this project\n",
    "- `Jupyter Notebook` - I used notebook to better understand the data as I process them visually.\n",
    "- `Python` - Python is used for creating the actual scripts to execute the whole process because it is one of the simplest languages to work with.\n",
    "- `Pandas` - I used pandas because pandas is convinient for checking, cleaning, merging and visualizing the results after each manipulation process.\n",
    "- `PySpark` - I used PySpark to work with large data, i94 immigration data, making use of distributed processing for more efficiency. I did not create a EMR cluster to use PySpark for this project since the project workspace did not recquired an EMR cluster, but if you do it locally you would need to create one.\n",
    "- `PostgreSQL` - I used PostgreSQL to create a database and tables because it is recommended to use for relational models, and also because I'm familiar with it.\n",
    "\n",
    "###### 2. How often this data should be updated and why\n",
    "\n",
    "* Monthly update is recommended since the original i94 data itself is updated on monthly basis.\n",
    "\n",
    "###### 3. How I would approach the problem differently under the following scenarios:\n",
    "\n",
    "* *The data was increased by 100x.*\n",
    "  *  I would use PySpark instead of pandas for all the data, and for writing into tables I would still use PostgreSQL, but suggest upgrading a hardware(i.e. better CPU, RAM, and SSD) to execute. If I wanted to use cloud infrustructure, I would use AWS S3 to write and load into those tables.\n",
    "* *The data populates a dashboard that must be updated on a daily basis by 7am every day.*\n",
    "  *  I would implement Apache Airflow to create a DAG file that executes ETL pipelines to run everyday before 7 am.\n",
    "* *The database needed to be accessed by 100+ people.*\n",
    "  *  I would probably stick to using PostgreSQL as a database, however, if it is too slow I would move them to cloud data warehouse such as Redshift on AWS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
